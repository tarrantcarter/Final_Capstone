{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Modern_Motivation_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlGN9q2hB1ms"
      },
      "source": [
        "!pip install pyLDAvis --quiet\n",
        "!pip install chart_studio --quiet\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S39PKkWJTM6_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import gensim\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from pprint import pprint\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import plotly.express as px\n",
        "import pyLDAvis.gensim\n",
        "import chart_studio\n",
        "import chart_studio.plotly as py \n",
        "import chart_studio.tools as tls\n",
        "from operator import itemgetter\n",
        "from ipywidgets import interact\n",
        "import tqdm\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "# widget packages\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# supress warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOCdohTeTVXy",
        "outputId": "7a87afae-9eca-47b1-af0a-04fb9e8ca84d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvJKQxX02eY"
      },
      "source": [
        "We will load in our cleaned tweets from our [data cleaning notebook](https://github.com/tarrantcarter/Final_Capstone/blob/main/Modern_Motivation_Data_Cleaning_Feature_Engineering.ipynb). The csv can be found here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BbNTyvSTM6_"
      },
      "source": [
        "# load in cleaned tweets from data cleaning notebook\n",
        "tweets_cleaned = pd.read_json(\"/content/drive/MyDrive/Data/NLP_Capstone/motivational_tweets_cleaned.json\"\n",
        "                    )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX1S_t80mNjl"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "7f_G-wOgTM7A",
        "outputId": "21071aa9-0faa-46c0-a2de-25e9e281b195"
      },
      "source": [
        "tweets_cleaned.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>user_name</th>\n",
              "      <th>display_name</th>\n",
              "      <th>content</th>\n",
              "      <th>content_preprocessed</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2021-01-17 22:13:17</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Lewis Howes</td>\n",
              "      <td>Know this. Everything is happening for a reaso...</td>\n",
              "      <td>know happen reason favor betterment future pai...</td>\n",
              "      <td>[know, happen, reason, favor, betterment, futu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>2021-01-15 15:28:06</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Lewis Howes</td>\n",
              "      <td>Protect your inner peace at all costs. Create ...</td>\n",
              "      <td>protect inner peace cost create daily practice...</td>\n",
              "      <td>[protect, inner, peace, cost, create, daily, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>2021-01-12 16:40:46</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Lewis Howes</td>\n",
              "      <td>You are stronger than you think. The painful m...</td>\n",
              "      <td>strong think painful moment hurt past mean bre...</td>\n",
              "      <td>[strong, think, painful, moment, hurt, past, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>2021-01-07 16:00:29</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Lewis Howes</td>\n",
              "      <td>Always remember to ask for exactly what you wa...</td>\n",
              "      <td>remember ask exactly want ask love good health...</td>\n",
              "      <td>[remember, ask, exactly, want, ask, love, good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>2021-01-05 00:11:24</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Lewis Howes</td>\n",
              "      <td>What if you treated yourself like someone you ...</td>\n",
              "      <td>treat like madly love imagine positive energy ...</td>\n",
              "      <td>[treat, like, madly, love, imagine, positive, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   date  ...                                          tokenized\n",
              "44  2021-01-17 22:13:17  ...  [know, happen, reason, favor, betterment, futu...\n",
              "61  2021-01-15 15:28:06  ...  [protect, inner, peace, cost, create, daily, p...\n",
              "108 2021-01-12 16:40:46  ...  [strong, think, painful, moment, hurt, past, m...\n",
              "161 2021-01-07 16:00:29  ...  [remember, ask, exactly, want, ask, love, good...\n",
              "206 2021-01-05 00:11:24  ...  [treat, like, madly, love, imagine, positive, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5gUYa2fu5rc",
        "outputId": "1501b9e8-251e-4df6-e026-6fcf7117d596"
      },
      "source": [
        "tweets_cleaned.applymap(type)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>user_name</th>\n",
              "      <th>display_name</th>\n",
              "      <th>content</th>\n",
              "      <th>content_preprocessed</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977606</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977607</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977608</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977609</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977610</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>694155 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     date  ...       tokenized\n",
              "44      <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "61      <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "108     <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "161     <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "206     <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "...                                                   ...  ...             ...\n",
              "977606  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "977607  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "977608  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "977609  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "977610  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...  <class 'list'>\n",
              "\n",
              "[694155 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30qByL1knIDP",
        "outputId": "2ec8b63d-cb16-4c54-91c0-0559604dd82a"
      },
      "source": [
        "tweets_cleaned.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 694155 entries, 44 to 977610\n",
            "Data columns (total 6 columns):\n",
            " #   Column                Non-Null Count   Dtype         \n",
            "---  ------                --------------   -----         \n",
            " 0   date                  694155 non-null  datetime64[ns]\n",
            " 1   user_name             694155 non-null  object        \n",
            " 2   display_name          694155 non-null  object        \n",
            " 3   content               694155 non-null  object        \n",
            " 4   content_preprocessed  694155 non-null  object        \n",
            " 5   tokenized             694155 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 37.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xOh3ReEndgg",
        "outputId": "86b0e314-e4fa-456d-be6e-0b47d0aed0f6"
      },
      "source": [
        "tweets_cleaned.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(694155, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHgDycOJX7MU"
      },
      "source": [
        "# Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7hq1gAeTM7O",
        "outputId": "4852a74b-9768-4b8b-b15b-85fc0d1b8a38"
      },
      "source": [
        "# create dictionary\n",
        "id2word = corpora.Dictionary(tweets_cleaned['tokenized'])\n",
        "# create texts corpus\n",
        "texts = tweets_cleaned['tokenized']\n",
        "# term document frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "# print first 30 tuples from corpus\n",
        "print(corpus[:1][0][:30])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOrtT9glftHi"
      },
      "source": [
        "# number of topics\n",
        "num_topics = 5\n",
        "# build LDA model\n",
        "base_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "# # print the keyword in the 10 topics\n",
        "# pprint(base_model.print_topics())\n",
        "# doc_lda = base_model[corpus]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "l8N7x_QGk4Om",
        "outputId": "a8ee09ea-7f75-4b5f-a0fa-eb168419a596"
      },
      "source": [
        "# filtering for words \n",
        "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]\n",
        "\n",
        "# create topic sorted by 10 most relevent words\n",
        "topics = [' '.join(t[0:10]) for t in words]\n",
        "\n",
        "\n",
        "# print most relevent words for each topic\n",
        "for id, t in enumerate(topics): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0dffa33405a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# filtering for words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\"([^\"]*)\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create topic sorted by 10 most relevent words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0dffa33405a8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# filtering for words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\"([^\"]*)\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create topic sorted by 10 most relevent words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBmHOCLAk5aZ"
      },
      "source": [
        "# Compute Perplexity\n",
        "## a measure of how good the model is. lower the better\n",
        "base_perplexity = base_model.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', base_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model = CoherenceModel(model=base_model, texts=tweets_cleaned['tokenized'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_base = coherence_model.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yKtvh9Qlvgu"
      },
      "source": [
        "# topic distance visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(base_model, corpus, id2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbH0VY_Gl3zw"
      },
      "source": [
        "get_document_topics = [base_model.get_document_topics(item) for item in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km4y6vNzY-oA"
      },
      "source": [
        "len(get_document_topics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXFAE9L6Y3UO"
      },
      "source": [
        "get_document_topics[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Msw50ipaxD"
      },
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHqifw2LoPta"
      },
      "source": [
        "# start preprocess runtime\n",
        "start_time = time.time() \n",
        "\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 15\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
        "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
        "               gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
        "               corpus]\n",
        "corpus_title = ['75% Corpus', '100% Corpus']\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=540)\n",
        "    \n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "                    \n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
        "    pbar.close()\n",
        "\n",
        "# print preprocess runtime\n",
        "print(time.strftime(f'%H hours, %M minutes, %S seconds', time.gmtime(time.time() - start_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lVjoUQ3dLcd"
      },
      "source": [
        "# Function to sort the list by second item of tuple \n",
        "def sort_tuple(tup):  \n",
        "  \n",
        "    # reverse = None (Sorts in Ascending order)  \n",
        "    # key is set to sort using second element of  \n",
        "    # sublist lambda has been used  \n",
        "    return(sorted(tup, key = lambda x: x[1],reverse=True))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4h8AIPFc3Ns"
      },
      "source": [
        "sort_tuple(get_document_topics[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mgZXwf1dh4F"
      },
      "source": [
        "sorted_tuples = [sort_tuple(tup) for tup in get_document_topics]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S8wZeZdd1Bf"
      },
      "source": [
        "sorted_tuples[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0oow1ALgNmS"
      },
      "source": [
        "def test(x):\n",
        "  if x[1] > .5:\n",
        "    return x[0]\n",
        "  return 'None'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxKv7-tNd506"
      },
      "source": [
        "highest_topic = [test(tup[0]) for tup in sorted_tuples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEr0MahIeBz0"
      },
      "source": [
        "highest_topic[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A25mt6YaGDE"
      },
      "source": [
        "max(get_document_topics[0],key = itemgetter(1))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baCC6lKjaZEe"
      },
      "source": [
        "topic_df = tweets_cleaned.copy()\n",
        "\n",
        "topic_df['best_topic_fit'] = highest_topic\n",
        "\n",
        "topic_df['best_topic_fit'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ2fTMJeTM7O"
      },
      "source": [
        "# tweet bot will have a drop down for topic and seperate one for twitter user account\n",
        "test = topic_df['content'].sample(5).reset_index()\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-V5NQZppH4T"
      },
      "source": [
        "# helper function to display ipywidgets in colab\n",
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))\n",
        "  from plotly.offline import init_notebook_mode\n",
        "  init_notebook_mode(connected=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kufiw1We1XPk"
      },
      "source": [
        "usernames = tweets_cleaned['user_name'].unique().tolist()\n",
        "usernames.insert(0,'All')\n",
        "usernames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azmxhjk09X3n"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "\n",
        "@interact(Topic=['All','None',0,1,2,3,4,5,6,7,8,9],User_Name=usernames,button=button)\n",
        "\n",
        "def topics(Topic,User_Name):\n",
        "  topic_filtered = topic_df[topic_df['best_topic_fit'] == Topic]\n",
        "  if Topic:\n",
        "    if Topic == 'All':\n",
        "      if User_Name == 'All':\n",
        "        quote = topic_df['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "      else:\n",
        "        user_name_filtered = topic_df[topic_df['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "    else:  \n",
        "      if User_Name == 'All':\n",
        "        quote = topic_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "      else:\n",
        "        user_name_filtered = topic_filtered[topic_filtered['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "  else:\n",
        "    return 'Sorry, there are no quotes for these categories'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIrAt8YPAEt8"
      },
      "source": [
        "def topics(Topic,User_Name):\n",
        "  topic_filtered = topic_df[topic_df['best_topic_fit'] == Topic]\n",
        "  if Topic:\n",
        "    if Topic == 'All':\n",
        "      if User_Name == 'All':\n",
        "        quote = topic_df['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "      else:\n",
        "        user_name_filtered = topic_df[topic_df['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "    else:  \n",
        "      if User_Name == 'All':\n",
        "        quote = topic_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "      else:\n",
        "        user_name_filtered = topic_filtered[topic_filtered['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        return quote.item()\n",
        "  else:\n",
        "    return 'Sorry, there are no quotes for these categories'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd-DQs83pZQH"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "\n",
        "# button = widgets.Button(description='My Button')\n",
        "# out = widgets.Output()\n",
        "\n",
        "@interact(Topic=['All','None',0,1,2,3,4,5,6,7,8,9],User_Name=usernames,Click_Me=True)\n",
        "\n",
        "def topics(Topic,User_Name,Click_Me):\n",
        "  topic_filtered = topic_df[topic_df['best_topic_fit'] == Topic]\n",
        "  if Topic:\n",
        "    if Topic == 'All':\n",
        "      if User_Name == 'All':\n",
        "        quote = topic_df['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "      else:\n",
        "        user_name_filtered = topic_df[topic_df['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "    else:  \n",
        "      if User_Name == 'All':\n",
        "        quote = topic_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "      else:\n",
        "        user_name_filtered = topic_filtered[topic_filtered['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "  else:\n",
        "    print('Sorry, there are no quotes for these categories')\n",
        "\n",
        "# def on_button_clicked(Topic):\n",
        "#       # \"linking function with output\"\n",
        "#       with out:\n",
        "#           # what happens when we press the button\n",
        "#           clear_output()\n",
        "#           topics(Topic,User_Name)\n",
        "#           print(Topic)\n",
        "# linking button and function together using a button's method\n",
        "# button.on_click(topics)\n",
        "# # displaying button and its output together\n",
        "# widgets.VBox([button,out])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP9nLKAV_fsO"
      },
      "source": [
        "btn = widgets.Button(description='Medium')\n",
        "display(btn)\n",
        "def btn_eventhandler(obj):\n",
        "    print('Hello from the {} button!'.format(obj.description))\n",
        "btn.on_click(btn_eventhandler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYfVA9PZSS_g"
      },
      "source": [
        "def unique_values(array):\n",
        "  unique = array.unique().tolist()\n",
        "  unique.insert(0,'All')\n",
        "  return unique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzgFGmYQS1Fn"
      },
      "source": [
        "dropdown_user = widgets.Dropdown(options = unique_values(tweets_cleaned['user_name']))\n",
        "#dropdown_topic = widgets.Dropdown(options = unique_values(topic_df['best_topic_fit']))\n",
        "dropdown_topic = widgets.Dropdown(options = ['All','None',0,1,2,3,4,5,6,7,8,9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj7BM8CFT9JU"
      },
      "source": [
        "dropdown_topic = widgets.Dropdown(options = ['All','None',0,1,2,3,4,5,6,7,8,9])\n",
        "\n",
        "output_topic = widgets.Output()\n",
        "\n",
        "def dropdown_topic_eventhandler(change):\n",
        "  #output_topic.clear_output(wait=True)\n",
        "  #with output_topic:\n",
        "    if (change.new == 'All'):\n",
        "      #quote = topic_df['content'].sample(1).reset_index(drop=True)\n",
        "      display(output_topic)\n",
        "    else:\n",
        "      #topic_filtered = topic_df[topic_df['best_topic_fit'] == change.new]\n",
        "      #quote = topic_filtered['content'].sample(1).reset_index(drop=True)\n",
        "      #display(quote.item())\n",
        "      display(tweets_cleaned.tail())\n",
        "\n",
        "dropdown_topic.observe(dropdown_topic_eventhandler, names='values')\n",
        "\n",
        "display(dropdown_topic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJmn2sKecDHw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = \"https://data.london.gov.uk/download/number-international-visitors-london/b1e0f953-4c8a-4b45-95f5-e0d143d5641e/international-visitors-london-raw.csv\"\n",
        "df_london = pd.read_csv(url, encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i5GAov0b0fG"
      },
      "source": [
        "ALL = 'ALL'\n",
        "def unique_sorted_values_plus_ALL(array):\n",
        "    unique = array.unique().tolist()\n",
        "    unique.sort()\n",
        "    unique.insert(0, ALL)\n",
        "    return unique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlMeBotDcAMt"
      },
      "source": [
        "dropdown_year = widgets.Dropdown(options = unique_sorted_values_plus_ALL(df_london.year))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi_8Y_7fcdAF"
      },
      "source": [
        "dropdown_year = widgets.Dropdown(options =    unique_sorted_values_plus_ALL(df_london.year))\n",
        "\n",
        "output_year = widgets.Output()\n",
        "\n",
        "display(dropdown_year)\n",
        "\n",
        "def dropdown_year_eventhandler(change):\n",
        "    # with output_year:\n",
        "    #   output_year.clear_output()\n",
        "      if (change.new == ALL):\n",
        "          display(df_london)\n",
        "      else:\n",
        "          display(df_london[df_london.year == change.new])\n",
        "\n",
        "dropdown_year.observe(dropdown_year_eventhandler, names='value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDWGuAyLUaxE"
      },
      "source": [
        "def topics(Topic,User_Name,Click_Me):\n",
        "  topic_filtered = topic_df[topic_df['best_topic_fit'] == Topic]\n",
        "  if Topic:\n",
        "    if Topic == 'All':\n",
        "      if User_Name == 'All':\n",
        "        quote = topic_df['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "      else:\n",
        "        user_name_filtered = topic_df[topic_df['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "    else:  \n",
        "      if User_Name == 'All':\n",
        "        quote = topic_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "      else:\n",
        "        user_name_filtered = topic_filtered[topic_filtered['user_name'] == User_Name]\n",
        "        quote = user_name_filtered['content'].sample(1).reset_index(drop=True)\n",
        "        print(quote.item())\n",
        "  else:\n",
        "    print('Sorry, there are no quotes for these categories')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eMnc002-8QC"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def on_button_clicked(_):\n",
        "      # \"linking function with output\"\n",
        "      with out:\n",
        "          # what happens when we press the button\n",
        "          clear_output()\n",
        "          topics('All','All')\n",
        "# linking button and function together using a button's method\n",
        "button.on_click(on_button_clicked)\n",
        "# displaying button and its output together\n",
        "widgets.VBox([button,out])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}