{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Modeling_Motivational_Tweet_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu0NRpV_yHdW"
      },
      "source": [
        "# Topic Modeling\n",
        "Topic modeling is an unsupervised method that involves both dimensionality reduction and clustering text data into meaningful topics. There are several common approaches for text data. One such approach is **LSA (Latent Semantic Analysis)**. The core idea behind LSA is to take a matrix that already contains documents (tweets) and words, then decompose those into two matrices, one document (tweet) to topic matrix, and one a topic to word matrix. This allows one to find similiarity of different documents and different words. However, there are several downsides to using LSA. One is a lack of interpretability compared to the other approaches I will discuss. LSA also needs a large set of documents for accurate results. \n",
        "\n",
        "Another approach to discuss is **PLSA (Probabilistic latent Semantic Analysis)**. PLSA adds a probabistic spin to LSA. So each document (tweet) will have a probability of belonging in each category. However, PLSA is prone to ovefitting because it scales linearly as number of parameters increase. \n",
        "\n",
        "The approach used for the project will be **LDA (Latent Dirichlet Allocation)**. LDA is really just a Bayesian version of PLSA. The benefit of modeling with LDA is that it generalizes the best of the 3 approaches. This has to do with the two parameters alpha and beta which take advantage of dirichlet distributions. A deeper discussion on dirichlet distributions can be found [here](https://medium.com/@souravboss.bose/comprehensive-topic-modelling-with-nmf-lsa-plsa-lda-lda2vec-part-2-e3921e712f11). LDA will be choosen for this project mainly for its ability generalize better than the alternatives. \n",
        "\n",
        "The entire project repo can be found [here](https://github.com/tarrantcarter/Final_Capstone). Step 1) [Web Scraping](https://github.com/tarrantcarter/Final_Capstone/blob/main/Web_Scrape_Motivational_Tweet_Generator.ipynb), Step 2) [Data Preprocessing](https://github.com/tarrantcarter/Final_Capstone/blob/main/Data_Preprocessing_Motivational_Tweet_Generator.ipynb), Step 3) [Modeling](https://github.com/tarrantcarter/Final_Capstone/blob/main/Modeling_Motivational_Tweet_Generator.ipynb), Step 4) [Optimized Model + Deployment](https://github.com/tarrantcarter/Final_Capstone/blob/main/Optimal_Deployed_Motivational_Tweet_Generator.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlGN9q2hB1ms"
      },
      "source": [
        "!pip install pyLDAvis --quiet\n",
        "!pip install chart_studio --quiet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S39PKkWJTM6_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import gensim\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from pprint import pprint\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import plotly.express as px\n",
        "import pyLDAvis.gensim\n",
        "import chart_studio\n",
        "import chart_studio.plotly as py \n",
        "import chart_studio.tools as tls\n",
        "from operator import itemgetter\n",
        "from ipywidgets import interact\n",
        "import tqdm\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "# widget packages\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# supress warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOCdohTeTVXy",
        "outputId": "e14743fb-e1cf-4ffd-e12f-ca90af4248f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvJKQxX02eY"
      },
      "source": [
        "We will load in our preprocessed tweets from our [data cleaning notebook](https://github.com/tarrantcarter/Final_Capstone/blob/main/Data_Preprocessing_Motivational_Tweet_Generator.ipynb). The csv can be found [here](https://drive.google.com/file/d/1-d-61YuocweY0F3rSnf-idL1ixbuKq4H/view?usp=sharing). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BbNTyvSTM6_"
      },
      "source": [
        "# load in cleaned tweets from data cleaning notebook\n",
        "tweets_cleaned = pd.read_json(\"/content/drive/MyDrive/Data/NLP_Capstone/motivational_tweets_cleaned.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "7f_G-wOgTM7A",
        "outputId": "683f29c7-f6d1-4142-fcdb-7015e246a612"
      },
      "source": [
        "tweets_cleaned.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>user_name</th>\n",
              "      <th>content</th>\n",
              "      <th>content_preprocessed</th>\n",
              "      <th>unigram_tokens</th>\n",
              "      <th>ngrams</th>\n",
              "      <th>ngram_tokens</th>\n",
              "      <th>nouns_only</th>\n",
              "      <th>nouns_verbs</th>\n",
              "      <th>bigrams_trigrams</th>\n",
              "      <th>bigrams_trigrams_strings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2021-01-17 22:13:17</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Know this. Everything is happening for a reaso...</td>\n",
              "      <td>know happen reason favor betterment future pai...</td>\n",
              "      <td>[know, happen, reason, favor, betterment, futu...</td>\n",
              "      <td>know_happen_reason favor betterment future pai...</td>\n",
              "      <td>[know_happen_reason, favor, betterment, future...</td>\n",
              "      <td>[reason, favor, betterment, future, pain, feel...</td>\n",
              "      <td>[know, reason, favor, betterment, future, pain...</td>\n",
              "      <td>[know_happen_reason]</td>\n",
              "      <td>know_happen_reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>2021-01-15 15:28:06</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Protect your inner peace at all costs. Create ...</td>\n",
              "      <td>protect inner peace cost create daily practice...</td>\n",
              "      <td>[protect, inner, peace, cost, create, daily, p...</td>\n",
              "      <td>protect inner_peace cost create daily_practice...</td>\n",
              "      <td>[protect, inner_peace, cost, create, daily_pra...</td>\n",
              "      <td>[peace, cost, practice, communicate, stress, d...</td>\n",
              "      <td>[peace, cost, practice, communicate, stress, d...</td>\n",
              "      <td>[inner_peace, daily_practice]</td>\n",
              "      <td>inner_peace daily_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>2021-01-07 16:00:29</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Always remember to ask for exactly what you wa...</td>\n",
              "      <td>remember ask exactly want ask love good health...</td>\n",
              "      <td>[remember, ask, exactly, want, ask, love, good...</td>\n",
              "      <td>remember ask exactly want ask love good health...</td>\n",
              "      <td>[remember, ask, exactly, want, ask, love, good...</td>\n",
              "      <td>[health, abundance, peace, ask, wisdom, creati...</td>\n",
              "      <td>[remember, health, abundance, peace, ask, wisd...</td>\n",
              "      <td>[health_abundance, ask_wisdom]</td>\n",
              "      <td>health_abundance ask_wisdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>2021-01-01 02:44:46</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>This will be your greatest year ever. All your...</td>\n",
              "      <td>great year work start pay earn happy love deep...</td>\n",
              "      <td>[great, year, work, start, pay, earn, happy, l...</td>\n",
              "      <td>great year work start pay earn happy love deep...</td>\n",
              "      <td>[great, year, work, start, pay, earn, happy, l...</td>\n",
              "      <td>[year, work, start, earn, love, embrace, fear,...</td>\n",
              "      <td>[year, work, start, pay, earn, love, embrace, ...</td>\n",
              "      <td>[massive_action]</td>\n",
              "      <td>massive_action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>2020-12-30 01:38:35</td>\n",
              "      <td>LewisHowes</td>\n",
              "      <td>Be grateful for the breakdown this year. It's ...</td>\n",
              "      <td>grateful breakdown year set massive breakthrou...</td>\n",
              "      <td>[grateful, breakdown, year, set, massive, brea...</td>\n",
              "      <td>grateful breakdown year set massive breakthrou...</td>\n",
              "      <td>[grateful, breakdown, year, set, massive, brea...</td>\n",
              "      <td>[year, breakthrough, money, mission, get, rela...</td>\n",
              "      <td>[year, set, breakthrough, money, come, mission...</td>\n",
              "      <td>[real_friend]</td>\n",
              "      <td>real_friend</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   date  ...     bigrams_trigrams_strings\n",
              "44  2021-01-17 22:13:17  ...           know_happen_reason\n",
              "61  2021-01-15 15:28:06  ...   inner_peace daily_practice\n",
              "161 2021-01-07 16:00:29  ...  health_abundance ask_wisdom\n",
              "274 2021-01-01 02:44:46  ...               massive_action\n",
              "317 2020-12-30 01:38:35  ...                  real_friend\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "X5gUYa2fu5rc",
        "outputId": "29427378-ac25-446f-8d00-5d6ea40ca7c5"
      },
      "source": [
        "tweets_cleaned.applymap(type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>user_name</th>\n",
              "      <th>content</th>\n",
              "      <th>content_preprocessed</th>\n",
              "      <th>unigram_tokens</th>\n",
              "      <th>ngrams</th>\n",
              "      <th>ngram_tokens</th>\n",
              "      <th>nouns_only</th>\n",
              "      <th>nouns_verbs</th>\n",
              "      <th>bigrams_trigrams</th>\n",
              "      <th>bigrams_trigrams_strings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977598</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977599</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977606</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977608</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977610</th>\n",
              "      <td>&lt;class 'pandas._libs.tslibs.timestamps.Timesta...</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'list'&gt;</td>\n",
              "      <td>&lt;class 'str'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>621449 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     date  ... bigrams_trigrams_strings\n",
              "44      <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "61      <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "161     <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "274     <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "317     <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "...                                                   ...  ...                      ...\n",
              "977598  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "977599  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "977606  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "977608  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "977610  <class 'pandas._libs.tslibs.timestamps.Timesta...  ...            <class 'str'>\n",
              "\n",
              "[621449 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30qByL1knIDP",
        "outputId": "e7661610-8408-4c0d-f8e2-dab496b7f64c"
      },
      "source": [
        "tweets_cleaned.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 621449 entries, 44 to 977610\n",
            "Data columns (total 11 columns):\n",
            " #   Column                    Non-Null Count   Dtype         \n",
            "---  ------                    --------------   -----         \n",
            " 0   date                      621449 non-null  datetime64[ns]\n",
            " 1   user_name                 621449 non-null  object        \n",
            " 2   content                   621449 non-null  object        \n",
            " 3   content_preprocessed      621449 non-null  object        \n",
            " 4   unigram_tokens            621449 non-null  object        \n",
            " 5   ngrams                    621449 non-null  object        \n",
            " 6   ngram_tokens              621449 non-null  object        \n",
            " 7   nouns_only                621449 non-null  object        \n",
            " 8   nouns_verbs               621449 non-null  object        \n",
            " 9   bigrams_trigrams          621449 non-null  object        \n",
            " 10  bigrams_trigrams_strings  621449 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(10)\n",
            "memory usage: 56.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xOh3ReEndgg",
        "outputId": "681f1db8-ecde-4155-851d-bedde0e11192"
      },
      "source": [
        "tweets_cleaned.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621449, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHgDycOJX7MU"
      },
      "source": [
        "# Base Topic Model\n",
        "In the next steps the LDA model will be created and optimized, but I haven't metioned exactly how it will be scored and optimized. Perplexity and Coherence scores will be computed initially for a base model. Our anaylsis will focus mostly on Coherence score instead of perplexity. This is mostly because Coherence score matches closer to the human intuition of topics than perplexity does. For a further discussion on perplexity vs coherence score check out the link [here](http://qpleple.com/topic-coherence-to-evaluate-topic-models/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7hq1gAeTM7O",
        "outputId": "378c6be4-a5bf-4cd5-8a31-6945843d0206"
      },
      "source": [
        "# create dictionary\n",
        "id2word = corpora.Dictionary(tweets_cleaned['nouns_only'])\n",
        "# create texts corpus\n",
        "texts = tweets_cleaned['nouns_only']\n",
        "# term document frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "# print first 30 tuples from corpus\n",
        "print(corpus[:1][0][:30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOrtT9glftHi"
      },
      "source": [
        "# number of topics\n",
        "num_topics = 10\n",
        "# build LDA model\n",
        "base_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8N7x_QGk4Om",
        "outputId": "6a632b86-05c9-4c7b-ec07-9382e91dafbb"
      },
      "source": [
        "# filtering for words \n",
        "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]\n",
        "\n",
        "# create topic sorted by 10 most relevent words\n",
        "topics = [' '.join(t[0:10]) for t in words]\n",
        "\n",
        "\n",
        "# print most relevent words for each topic\n",
        "for id, t in enumerate(topics): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ Topic 0 ------\n",
            "life power robert desire courage care difference question limit amp\n",
            "\n",
            "------ Topic 1 ------\n",
            "thing change einstein life albert churchill winston control end get\n",
            "\n",
            "------ Topic 2 ------\n",
            "amp dream problem feel energy fear think solve tzu obstacle\n",
            "\n",
            "------ Topic 3 ------\n",
            "mind peace moment opportunity body passion life place act define\n",
            "\n",
            "------ Topic 4 ------\n",
            "dyer life success world work person amp way failure fall\n",
            "\n",
            "------ Topic 5 ------\n",
            "look choice franklin soul henry truth life benjamin david mean\n",
            "\n",
            "------ Topic 6 ------\n",
            "day matter judge treat trust ralph life emerson hold bonaparte\n",
            "\n",
            "------ Topic 7 ------\n",
            "reality action result strength napoleon word practice abundance self power\n",
            "\n",
            "------ Topic 8 ------\n",
            "time heart john love today tomorrow bhajan anger defeat aim\n",
            "\n",
            "------ Topic 9 ------\n",
            "man way proverb create step lincoln peale experience learn jim\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBmHOCLAk5aZ",
        "outputId": "a1b741fb-aea2-4061-d2c1-4437ef88374f"
      },
      "source": [
        "# Compute Perplexity\n",
        "## a measure of how good the model is. lower the better\n",
        "base_perplexity = base_model.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', base_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model = CoherenceModel(model=base_model, texts=tweets_cleaned['nouns_only'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_base = coherence_model.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_base)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -6.94619580004618\n",
            "\n",
            "Coherence Score:  0.6164812244561871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "3yKtvh9Qlvgu",
        "outputId": "0b887ea5-cae4-43ab-f88e-1113421a185f"
      },
      "source": [
        "# topic distance visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(base_model, corpus, id2word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el56021397746459953448123915690\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el56021397746459953448123915690_data = {\"mdsDat\": {\"x\": [-0.004427059260828671, 0.22219410463306735, 0.08077142492876889, 0.04401127425728425, 0.08528175853494313, -0.16545957991232657, 0.21484586237673306, -0.0027750849903968554, -0.2315497052302077, -0.24289299533703704], \"y\": [-0.058685199714804535, -0.2024814514385216, -0.09712445392680742, -0.223311267396174, 0.21344279223455398, -0.07481167210799018, 0.2101008971280717, 0.18072141057544278, -0.013116685710891935, 0.06526563035712139], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.182809977468544, 11.999510707378901, 10.576747517758193, 10.40909325429426, 9.961151136666233, 9.489423063808774, 9.15881302190406, 8.990485418171536, 8.732031823043124, 8.499934079506374]}, \"tinfo\": {\"Term\": [\"dyer\", \"time\", \"thing\", \"man\", \"heart\", \"change\", \"look\", \"choice\", \"einstein\", \"mind\", \"amp\", \"peace\", \"day\", \"john\", \"way\", \"dream\", \"matter\", \"problem\", \"today\", \"love\", \"success\", \"franklin\", \"power\", \"reality\", \"feel\", \"albert\", \"proverb\", \"life\", \"moment\", \"action\", \"fall\", \"william\", \"climb\", \"frustration\", \"child\", \"confuciu\", \"anthony\", \"inspire\", \"search\", \"mandela\", \"consist\", \"stop\", \"ground\", \"optimism\", \"speed\", \"weather\", \"glory\", \"dale\", \"memory\", \"celebrate\", \"pressure\", \"mountain\", \"commitment\", \"chop\", \"bertrand\", \"russell\", \"harder\", \"root\", \"wisdom\", \"destination\", \"dyer\", \"work\", \"success\", \"god\", \"failure\", \"fight\", \"covey\", \"door\", \"fortune\", \"fail\", \"deserve\", \"talent\", \"anxiety\", \"rise\", \"try\", \"family\", \"guidance\", \"stephen\", \"happiness\", \"person\", \"world\", \"sense\", \"amp\", \"respect\", \"life\", \"way\", \"day\", \"love\", \"lincoln\", \"peale\", \"vincent\", \"fool\", \"abraham\", \"history\", \"gandhi\", \"mahatma\", \"voltaire\", \"source\", \"nature\", \"knowledge\", \"cross\", \"repeat\", \"worry\", \"fire\", \"stone\", \"existence\", \"wise\", \"deal\", \"pickford\", \"shadow\", \"rate\", \"dawn\", \"eleanor\", \"till\", \"river\", \"hubbard\", \"case\", \"clement\", \"man\", \"proverb\", \"jim\", \"hand\", \"beauty\", \"future\", \"step\", \"speak\", \"brault\", \"game\", \"presence\", \"experience\", \"rohn\", \"create\", \"learn\", \"woman\", \"goal\", \"way\", \"reason\", \"roosevelt\", \"person\", \"einstein\", \"albert\", \"churchill\", \"winston\", \"change\", \"hell\", \"fuller\", \"forget\", \"communication\", \"maya\", \"lesson\", \"influence\", \"perception\", \"teacher\", \"rain\", \"hepburn\", \"cash\", \"accomplishment\", \"gogh\", \"fantasy\", \"reject\", \"darkness\", \"precede\", \"hang\", \"bridge\", \"attitude\", \"position\", \"push\", \"conscience\", \"reputation\", \"thing\", \"control\", \"value\", \"victor\", \"pain\", \"ignorance\", \"get\", \"michael\", \"drive\", \"harry\", \"pull\", \"eye\", \"end\", \"difficulty\", \"gift\", \"form\", \"character\", \"decision\", \"life\", \"edison\", \"roosevelt\", \"way\", \"heart\", \"defeat\", \"tomorrow\", \"aim\", \"monroe\", \"waste\", \"force\", \"john\", \"yogi\", \"anger\", \"shakespeare\", \"ppl\", \"ruth\", \"strike\", \"sort\", \"shut\", \"dig\", \"today\", \"chance\", \"c\", \"twain\", \"wilde\", \"light\", \"conversation\", \"creation\", \"jack\", \"scott\", \"reward\", \"yesterday\", \"tension\", \"time\", \"asset\", \"thinking\", \"meet\", \"race\", \"bhajan\", \"dare\", \"love\", \"hoffer\", \"lead\", \"play\", \"person\", \"dog\", \"mark\", \"life\", \"tzu\", \"enemy\", \"solve\", \"jump\", \"percent\", \"lao\", \"road\", \"attempt\", \"freedom\", \"sea\", \"lewis\", \"joy\", \"tracy\", \"mistake\", \"solution\", \"rice\", \"read\", \"version\", \"strategy\", \"space\", \"imperfection\", \"ease\", \"star\", \"feel\", \"enthusiasm\", \"death\", \"arise\", \"jerry\", \"bar\", \"blessing\", \"problem\", \"energy\", \"fear\", \"dream\", \"sun\", \"achievement\", \"expectation\", \"doubt\", \"obstacle\", \"stand\", \"hope\", \"challenge\", \"think\", \"night\", \"feeling\", \"amp\", \"leader\", \"ability\", \"use\", \"strength\", \"life\", \"power\", \"treat\", \"ralph\", \"trust\", \"emerson\", \"bonaparte\", \"water\", \"jonathan\", \"waldo\", \"foot\", \"shoe\", \"greatness\", \"ego\", \"letter\", \"imagination\", \"inspiration\", \"confucius\", \"carl\", \"enjoy\", \"opinion\", \"attain\", \"release\", \"bach\", \"discover\", \"content\", \"discourage\", \"mother\", \"battle\", \"goethe\", \"heal\", \"perfection\", \"matter\", \"hold\", \"jung\", \"huie\", \"help\", \"judge\", \"lockwood\", \"year\", \"count\", \"willingness\", \"refuse\", \"day\", \"life\", \"idea\", \"act\", \"ability\", \"napoleon\", \"harm\", \"seneca\", \"intent\", \"victory\", \"bite\", \"risk\", \"cruelty\", \"patience\", \"smile\", \"benefit\", \"hill\", \"wind\", \"lengthen\", \"weakness\", \"make\", \"hate\", \"judgment\", \"sail\", \"alcott\", \"maxwell\", \"result\", \"absence\", \"ship\", \"b\", \"trouble\", \"page\", \"nietzsche\", \"buffett\", \"earth\", \"self\", \"word\", \"intention\", \"silence\", \"abundance\", \"need\", \"watch\", \"win\", \"kind\", \"reality\", \"action\", \"practice\", \"genius\", \"strength\", \"power\", \"way\", \"robert\", \"pessimist\", \"dalai\", \"denis\", \"desire\", \"limit\", \"care\", \"kennedy\", \"impact\", \"truman\", \"relationship\", \"stevenson\", \"discouragement\", \"norman\", \"winfrey\", \"speech\", \"coco\", \"waitley\", \"sight\", \"plant\", \"seed\", \"shore\", \"oprah\", \"travel\", \"rule\", \"beat\", \"lama\", \"disney\", \"bittersweet\", \"expertise\", \"hemingway\", \"consent\", \"difference\", \"grow\", \"sir\", \"understand\", \"find\", \"mediocrity\", \"quality\", \"start\", \"choose\", \"courage\", \"honor\", \"question\", \"power\", \"life\", \"amp\", \"answer\", \"bind\", \"peter\", \"define\", \"miracle\", \"fact\", \"eliot\", \"journey\", \"pocket\", \"buddha\", \"forgiveness\", \"decide\", \"teach\", \"order\", \"childhood\", \"impossibility\", \"music\", \"mind\", \"universe\", \"thatcher\", \"elliot\", \"react\", \"jefferson\", \"receive\", \"stuff\", \"war\", \"stress\", \"breath\", \"disease\", \"conflict\", \"shell\", \"peace\", \"moment\", \"path\", \"talk\", \"storm\", \"prevent\", \"drucker\", \"attention\", \"attract\", \"opportunity\", \"want\", \"passion\", \"dance\", \"body\", \"suit\", \"spirit\", \"place\", \"george\", \"act\", \"thomas\", \"life\", \"day\", \"franklin\", \"henry\", \"habit\", \"thoreau\", \"danger\", \"soul\", \"dr\", \"truth\", \"finger\", \"look\", \"lady\", \"martin\", \"show\", \"choice\", \"strengthen\", \"windshield\", \"mail\", \"mirror\", \"controversy\", \"mlk\", \"buy\", \"slip\", \"edge\", \"rearview\", \"jr\", \"tooth\", \"distance\", \"brick\", \"brinkley\", \"buffet\", \"david\", \"king\", \"wait\", \"mean\", \"business\", \"kill\", \"benjamin\", \"connection\", \"let\", \"effort\", \"wealth\", \"gain\", \"management\", \"ask\", \"lie\", \"point\", \"job\", \"world\", \"life\", \"act\", \"place\"], \"Freq\": [99079.0, 39704.0, 35778.0, 32572.0, 19702.0, 18984.0, 16325.0, 13533.0, 12368.0, 11158.0, 20936.0, 10074.0, 18121.0, 9619.0, 24246.0, 9150.0, 8702.0, 8770.0, 8793.0, 12152.0, 9516.0, 7605.0, 15798.0, 7922.0, 7538.0, 7672.0, 8094.0, 59430.0, 7136.0, 8321.0, 4583.207066726905, 3023.842551224654, 2408.779601946709, 2266.8196917605833, 2180.6913795659348, 1506.266094487242, 1483.2064706778763, 1976.8708895347063, 1298.1197831383563, 1142.2769469252273, 1239.5693216003701, 2182.2284217368997, 1057.0444627652143, 964.8045912364087, 944.4065084391493, 960.0352600337285, 1015.7076899314808, 901.6296531595085, 1165.0665423732544, 960.6359423900301, 778.5360135067776, 1303.6172412756255, 722.0034015201526, 651.9165218790409, 649.3926100011541, 649.4123597819147, 851.307831112813, 650.5660359995107, 4239.223965373326, 626.4190044006755, 98844.99756513441, 7471.72604698837, 9396.157896690114, 2688.888471592419, 5148.486255058387, 2078.2706680915, 2109.089822488169, 1732.3397016013093, 1429.6176770576421, 1986.1787478819804, 1274.458995270719, 1061.3069058665637, 1063.1596004568612, 2001.0128288555754, 2983.4971210447043, 1106.0491051828608, 1402.2290664605318, 1426.210667840035, 4279.67426895355, 7194.903210551289, 8240.282365529181, 1703.260454719445, 7060.2727399080295, 2767.1812819176753, 12418.483774855667, 5932.176823714525, 4092.019972286029, 2558.4452297286584, 6280.063498500737, 6124.023304791114, 4442.276533990211, 3929.606852511788, 3923.5983618385967, 3379.6236360247626, 2548.8317290866617, 2348.429234507398, 2249.380911438854, 2163.0585401665803, 2115.4870296543727, 2018.3239173021916, 1971.894757455605, 1496.2726453982762, 1847.702655045495, 1433.2341921726447, 1889.8066884725606, 1373.7164618006395, 1599.892268946952, 1314.3403899602083, 1298.918181519913, 1298.301119667545, 1269.597983327378, 1270.4846708441487, 2600.024546787833, 1254.5001661464669, 1254.3886015804521, 1269.3800054146784, 1267.837757458968, 1220.6592307582755, 32484.758150417227, 8076.932972289334, 5057.3923099189005, 2690.9386878591554, 2209.105425315522, 3878.569655857743, 7304.784172904372, 1942.2620971431866, 2529.6038540287514, 2570.13446106732, 3883.6517404019614, 5676.186056449184, 3995.9648599203706, 7368.316600952066, 5526.993188813117, 3852.1823992816044, 3802.27603082889, 12102.904769273966, 4096.69993620267, 3283.8142098891344, 2230.2697521662885, 12367.399461087345, 7672.064098133316, 7423.112327328928, 7204.210670729754, 18978.87671919965, 2635.2923538937084, 2559.763207539887, 2791.937786517039, 2259.6962756343046, 1969.6191642362269, 2756.0634732517237, 1904.7870728031044, 1579.5402538728763, 1645.6871632622056, 1514.603134724059, 1479.9540253230605, 1476.5718700096843, 1289.915514410658, 1275.0297773495752, 1230.5940922014777, 1250.287924006087, 1016.3339676203714, 992.237694194857, 990.2298008519747, 1438.5753755629628, 1350.9476098912864, 938.9439547770947, 1628.6234453118334, 882.2914791953036, 1654.0987003833477, 35671.32563761064, 5701.42871009506, 3510.1930602172224, 1800.3536777656984, 1987.1204379259327, 1448.0983663944498, 3997.7102090905187, 2235.7917763654345, 1643.0780788481986, 1646.7320635736403, 1604.586556157878, 3884.470974927656, 4143.22843915208, 3048.7796599132275, 2546.9041827809833, 2428.58036452975, 2725.8984140379775, 2600.0126002567176, 9029.850458090352, 2897.2582415786983, 2390.8865267427045, 3427.349970139725, 19701.338284476577, 3950.6687632261383, 4662.627708873484, 3835.5046196764524, 3045.6493236241417, 2707.6862745816948, 2586.046604149098, 9615.981033923134, 2194.6340002426487, 4002.409478897461, 2026.8163960578652, 1885.5468293307779, 1794.2977327100741, 1777.816700708287, 1715.9445394573556, 1700.7668912713996, 2051.9887309477695, 8789.196372966986, 1659.1564452650184, 1541.1898618832427, 1534.078400348941, 1472.3487599555326, 1230.6899470915996, 1226.7977871384965, 1217.781343845221, 1220.7004344121817, 1164.0047671125947, 1231.7082891923842, 1167.4901781827168, 1038.1009949180286, 39405.77345781762, 2768.457544522286, 2269.785765817092, 1910.24668170787, 2371.1216232600946, 4344.259161094081, 1785.6768671104521, 9255.882096841413, 2453.568057873808, 2311.579889694308, 2294.3017051404167, 3314.202598406385, 2108.0909141154098, 1753.1789366255612, 2532.136325918944, 4087.176069437296, 4006.212217296177, 4490.968596686873, 3263.274685398267, 2914.4218506552684, 2673.03798546862, 2520.695677480067, 2325.2013062613332, 2589.263107271898, 1861.3588256870426, 1816.3750942780366, 2901.9142476117077, 1948.5886327051862, 1800.4509355069276, 1663.2876055632948, 1655.6243524263655, 1658.040169374391, 1410.2667901990665, 1411.1483585785536, 1314.887595834217, 1302.1939789367768, 1191.893952794884, 1155.3811099912248, 7532.343946100874, 1458.4299743772879, 977.3509977276268, 967.6089581885695, 950.9857564287732, 1409.5177834165968, 925.959297234944, 8756.801238838189, 6886.940916095554, 5978.640556561791, 9082.855954577632, 3039.6434962916746, 3926.425440116692, 2434.651497784655, 2335.670296493713, 4060.082639603382, 2585.50727037711, 2251.262543575746, 2503.412931136128, 4714.178019354058, 2390.2809481601557, 1831.3247340082523, 9705.231977388961, 3193.6035509005374, 3190.6478098926723, 2425.4669371519008, 2952.0952263537006, 3111.301029185461, 2404.4175509307343, 6309.961691928593, 4748.2422849612585, 5410.76796499508, 3756.3686062799084, 3422.4094226215975, 3397.2289691689407, 2946.9123517578314, 2931.290882474083, 2485.295147172161, 2438.0934819618246, 3137.420307668714, 2262.521546016819, 2050.12102069756, 1989.5450536418912, 2135.9057425227325, 1633.5546884438297, 1584.635540668335, 1684.1070580456897, 1590.5466566188284, 1535.254030849052, 2938.0997076187987, 1558.6234144274315, 1444.661408420621, 1480.7119259855033, 1386.6254845519486, 1320.2651142598502, 1389.7925519898417, 1290.6396388309286, 1231.4375720658204, 1252.5303076674022, 8689.185218790428, 3425.144358967789, 2754.1683774121393, 2946.5991076372775, 2628.5036696872367, 6714.967257856296, 2261.206392399107, 2826.6062410931636, 1686.476328513986, 1769.0434907791637, 2894.950919623268, 11004.38473482743, 4466.084159308713, 1971.8747405415697, 2455.1017157710644, 2069.4774061894186, 5183.074251487272, 3331.018465628493, 3307.4612927945063, 2952.47947440804, 2821.139632572691, 2778.9126568569586, 2762.3068148484294, 2071.9288713547626, 2127.46895342486, 2078.0241157422315, 2053.256171395392, 1919.1080266714898, 2259.788835233696, 1806.3535585985496, 2027.3707828220263, 1788.724013518053, 1749.671821010351, 1609.9822910605164, 1559.681470406957, 1552.567592833363, 1494.4717709633187, 6969.991316304208, 2063.359522676118, 1398.814716891521, 1366.9884567812398, 1358.5391298898887, 1375.9397023710055, 1332.7540008957362, 1265.2835462345424, 1728.3193242484776, 3883.555318163704, 4650.7842467320215, 3051.2354703343462, 2417.463112674181, 4127.641143773236, 1812.9466864691708, 1656.2497588586639, 3401.124019323129, 3298.7036340702803, 7683.397509031306, 7453.953927603357, 4579.067917878259, 2205.973962888885, 6362.652101822523, 3777.242916056688, 2687.432464450035, 6204.016558065039, 3987.750923206234, 3476.392385017853, 2748.6049568028084, 6125.8416219322135, 4173.705908871243, 4576.211459986442, 2076.8993360246964, 2235.9504433187867, 1842.101113402404, 3309.4811266164234, 1638.7451202568634, 1628.3311056065072, 1603.0077889558672, 1594.795510391632, 1568.2468064414693, 1423.0604003705728, 1359.8700262454024, 1385.8736283607918, 1654.5010719487193, 1424.3833920791167, 1385.77947717748, 1388.623208549161, 1128.138369618509, 3375.095868320508, 1079.3385011135174, 3737.5240943762433, 1031.3483124719155, 938.4207898467348, 937.0782975694792, 3722.560251722844, 2766.6744681544924, 4555.002153941227, 2119.803634154604, 1702.2599960332543, 1684.8902707150316, 1499.954189765216, 2347.8166745197964, 1600.265724611689, 3548.3986412481677, 3367.451035992695, 5612.164547376365, 1751.5398629118508, 4433.398232501591, 8120.391071941433, 15084.699053038445, 4089.6580514613684, 2029.9145438918367, 3594.0713328673496, 3504.7413261814027, 4027.0830045640937, 3840.760586768728, 3159.8490809774325, 2538.5560849113317, 2012.1959747531298, 1850.9378543666628, 1611.5988898519904, 1599.9039473160103, 2044.1611316791054, 1749.9431893787078, 1803.5123493837175, 1384.9019653663436, 1377.9541504897531, 1394.928710245321, 11150.742545869713, 1247.0848285313075, 1235.3022886019492, 1184.3144896216245, 1223.9135423599394, 1567.0614354162672, 1135.4986719559404, 2254.3846166325643, 1193.1652789527852, 1196.395235542179, 1394.9221996282456, 1011.4153859043324, 2023.7933566786921, 836.7443092396842, 10033.114235391487, 7069.188562189951, 3136.4674821453864, 3322.143375936022, 2958.1154406903024, 1828.556720358537, 2761.2564769698124, 1761.8773477693526, 3758.3286775198867, 6798.523664971252, 2573.4241878872317, 5589.029758393351, 2613.965011250076, 6731.9330735240055, 2797.2923478993284, 3472.429725510445, 4250.9756287130795, 2613.1113312474913, 4195.453480876875, 2226.610126897458, 4749.321145470091, 2499.0549873662876, 7604.8839623274025, 6373.129498044288, 4422.2972834136, 2462.757831134844, 2339.757224671128, 6713.82929021393, 2168.493759043709, 6105.749183031273, 2016.0772503643586, 16317.859987089761, 1844.1832930807802, 2217.0306698654504, 2343.8182592617904, 13525.962273702791, 1561.9318826827903, 1300.5541055799451, 1263.8762185211242, 1309.988242685389, 1058.6909382557012, 1058.6843126199603, 1053.0099837382324, 1051.7988367295304, 1018.0051177158515, 1300.2774612818343, 985.2720765629608, 857.5126312342433, 802.9292996685112, 802.0878919412653, 793.0047214826785, 786.3184467711555, 5063.5547334386165, 4068.3189490294685, 3427.0937629697996, 4922.662990000242, 3335.0780860841373, 1838.961908022096, 5064.3044865381125, 1275.9027076279895, 3575.322485766052, 2915.0976650651533, 1251.6111105038788, 1821.0390832243281, 1308.0346403788762, 2235.089272184054, 4254.619535030211, 1844.3893599546939, 1980.6289468658667, 3511.2074570091836, 5120.974221196295, 2892.1383968672094, 2660.8787433448315], \"Total\": [99079.0, 39704.0, 35778.0, 32572.0, 19702.0, 18984.0, 16325.0, 13533.0, 12368.0, 11158.0, 20936.0, 10074.0, 18121.0, 9619.0, 24246.0, 9150.0, 8702.0, 8770.0, 8793.0, 12152.0, 9516.0, 7605.0, 15798.0, 7922.0, 7538.0, 7672.0, 8094.0, 59430.0, 7136.0, 8321.0, 4584.282224019752, 3024.7449410419717, 2409.6862778555173, 2267.746867052166, 2181.7112436628354, 1507.16844661207, 1484.123561981644, 1978.2265524396896, 1299.022026676186, 1143.1814290282211, 1240.6142330993184, 2184.0891017419967, 1057.946771738532, 965.7220014402762, 945.3119178075037, 960.9681968357529, 1016.7073956665045, 902.5382877219738, 1166.2620931538838, 961.6259273853491, 779.4382375970813, 1305.1563967709242, 722.9680000785257, 652.8202862008013, 650.2956804617313, 650.3156014186662, 852.4932197224566, 651.4721187012958, 4245.139393444638, 627.3213909770413, 99079.51452229792, 7485.049069601161, 9516.579978320053, 2696.8273320465346, 5197.980338997914, 2084.7410658255326, 2116.517034828602, 1738.0300329859456, 1431.9943653489438, 1999.092662846385, 1277.3083690732049, 1063.5012265944092, 1065.6743665935505, 2032.4105149862924, 3274.8661635379967, 1113.8523276038104, 1457.6073936684884, 1529.4278927909338, 6107.683199382006, 12761.384570563223, 16506.567259697065, 2033.4262968947887, 20936.258144774198, 4645.810970781434, 59430.17528032143, 24246.815896851436, 18121.704024383, 12152.859730389899, 6280.95838764177, 6124.927129729286, 4443.170311442742, 3930.486918392412, 3924.490342181148, 3380.56157010076, 2549.7189073759064, 2349.3174166012673, 2250.262840057395, 2163.9754813876825, 2116.4397068973094, 2019.287345876758, 1972.8711762397345, 1497.1528467106975, 1848.8018680416535, 1434.117171071969, 1891.0135501035475, 1374.5990541997737, 1600.9666668190837, 1315.2233805662652, 1299.7983091929825, 1299.1812834255236, 1270.478519010024, 1271.3662223308186, 2601.8395132233004, 1255.3802753409282, 1255.2692141274235, 1270.2727491540122, 1268.7394616770302, 1221.5396958318217, 32572.294526956233, 8094.480122882934, 5061.742553207651, 2693.7276925994565, 2222.293664280628, 3924.1921797944474, 7526.490881361156, 1953.000420439558, 2561.667446328164, 2605.260102518402, 3978.248503849859, 6066.983930746509, 4243.740013798527, 8205.921031473734, 7214.861439538777, 4823.025138143238, 4786.275045244215, 24246.815896851436, 5977.485958930438, 5684.34536552706, 12761.384570563223, 12368.321379787603, 7672.950364905969, 7424.017171408108, 7205.125860976622, 18984.992252739125, 2636.174719883758, 2560.6441464543054, 2792.953666816491, 2260.577340691384, 1970.5396671645192, 2757.37926592718, 1905.7035738370173, 1580.424020303049, 1646.6084808471976, 1515.5027814097245, 1480.8351214409518, 1477.4561741184973, 1290.800247518347, 1275.9108403920834, 1231.4752938565264, 1251.2213676992176, 1017.2148370971898, 993.1187704718543, 991.1106301374525, 1439.893810512623, 1352.2089109872059, 939.8364719414509, 1630.2472352873895, 883.1724390667385, 1655.758303565289, 35778.73584333546, 5708.809000061609, 3526.0683041447514, 1802.784827145151, 1994.229381557839, 1450.434701065918, 4083.226200601439, 2262.879865605191, 1666.099997678816, 1671.6483657694023, 1628.104990503555, 4944.394243214541, 5403.37160855924, 4055.16388068463, 3236.111090673523, 3141.4963988081327, 4285.472635723048, 4025.0406885042735, 59430.17528032143, 5678.334972757704, 5684.34536552706, 24246.815896851436, 19702.846229672617, 3951.5333624822924, 4663.741152326481, 3836.437233181289, 3046.511408625136, 2708.565189797096, 2586.9476250027487, 9619.463076596488, 2195.4957289932236, 4004.008772341833, 2027.6783686711265, 1886.4087338726383, 1795.1594376050336, 1778.6784789257129, 1716.8076626494594, 1701.6298286586646, 2053.105258959049, 8793.981970425504, 1660.0706707311326, 1542.0544074687446, 1534.964767555449, 1473.2104732084329, 1231.5517383502513, 1227.6596078236846, 1218.6440139083659, 1221.5668421010998, 1164.8786384885984, 1232.7009203916, 1168.4582078299306, 1038.96278075864, 39704.08153557995, 2773.999625170215, 2273.780785012793, 1915.3876167538062, 2422.4236914605904, 4581.537725451169, 1835.4324255134882, 12152.859730389899, 2778.759868312773, 3065.6459954024754, 3169.832131518285, 12761.384570563223, 3995.8463431526534, 1966.5670933008703, 59430.17528032143, 4088.0609384473146, 4007.0819789332427, 4492.089514888237, 3264.1445700693785, 2915.3110492538817, 2673.930706310074, 2521.5900093554774, 2326.0711382636255, 2590.3920761862214, 1862.2309081221083, 1817.2449184432319, 2903.3462266454603, 1949.5695129356002, 1801.3654532245155, 1664.1612382978842, 1656.4942392255664, 1658.9353064367879, 1411.1418874169515, 1412.0329591658779, 1315.7582176985024, 1303.0638063743627, 1192.763943456347, 1156.2614545615052, 7538.626747636601, 1459.688239694459, 978.2208821228115, 968.4787758009106, 951.8555660964598, 1410.81587887938, 926.8305650032692, 8770.024784723071, 6896.96893151886, 5987.8376788944, 9150.9514743499, 3044.551834040113, 3943.5009424739887, 2437.902560122208, 2338.022206789053, 4088.5585499064246, 2597.263790614335, 2261.7393228074015, 2532.5856518854034, 4956.372519815664, 2468.4377604132205, 1856.7620133911857, 20936.258144774198, 4567.441181537982, 5331.092358612086, 3528.364745290039, 9316.01744189032, 59430.17528032143, 15798.36978965918, 6310.982417271981, 4749.128267492776, 5412.125913799752, 3757.316307826568, 3423.2817432620004, 3398.10131691902, 2947.7854715255007, 2932.1928305001284, 2486.167444410388, 2438.9662235787, 3138.5884132737997, 2263.4020539925104, 2051.015256871471, 1990.4174710991967, 2137.0185551739387, 1634.4269800171694, 1585.5089564102618, 1685.0548231955154, 1591.4679029014985, 1536.1660213071443, 2939.8501370999297, 1559.5674009447443, 1445.5389072588819, 1481.6407734053582, 1387.498032249745, 1321.1374343470839, 1390.7195678706487, 1291.5276614887036, 1232.3099684046035, 1253.4377026543796, 8702.181160131178, 3429.115193203999, 2756.2955513903908, 2952.025040371878, 2632.5729451458888, 6789.986598333843, 2266.7548096187907, 2910.849421541408, 1696.8882876078026, 1785.5822160718378, 3089.022540825393, 18121.704024383, 59430.17528032143, 3350.026399371727, 10758.004782683867, 5331.092358612086, 5184.169361507767, 3331.897201105194, 3308.3613192651087, 2953.3538383313476, 2822.0162735387707, 2779.785230812284, 2763.3048143639653, 2072.80301182333, 2128.4207112821277, 2079.000477578472, 2054.2225518872815, 1920.0160923336127, 2260.8603640307633, 1807.235002822513, 2028.3630849073963, 1789.6233266611796, 1750.6033106956625, 1610.8646167534575, 1560.5573814707523, 1553.447739394627, 1495.3436908692645, 6974.087244588936, 2064.5728962565345, 1399.6865874260257, 1367.8623418443242, 1359.4110135726123, 1376.8381587104147, 1333.62591682887, 1266.1554165416771, 1729.5283853913136, 3888.203476688962, 4666.438964218416, 3058.580785397752, 2419.5895367615567, 4166.439789138449, 1815.7243135133917, 1658.0983455221526, 3431.3804661095246, 3326.9263851556575, 7922.526806543877, 8321.969019768567, 5359.692676239081, 2299.6040422255887, 9316.01744189032, 15798.36978965918, 24246.815896851436, 6204.8934459292595, 3988.6588038305454, 3477.2728976819576, 2749.489986004944, 6128.005243425439, 4175.319767692472, 4578.042955159892, 2077.7752002332154, 2236.9487108238022, 1842.9734624056377, 3311.136656067718, 1639.6180771528736, 1629.2024100877152, 1603.8800282299262, 1595.669184795337, 1569.1273175089325, 1423.939650934434, 1360.755032910672, 1386.7968907895895, 1655.6053782537692, 1425.3534002450954, 1386.7391137662516, 1389.627588031714, 1129.0097517283973, 3377.7631358426406, 1080.209883752967, 3740.630583340852, 1032.2514725482768, 939.2923077845234, 937.9496407620387, 3726.1496323250312, 2771.1844141094325, 4598.03835927527, 2126.311217419291, 1704.1501634641488, 1687.6142360427982, 1501.5606883389412, 2371.9091316881945, 1604.5861934168672, 3618.219934044535, 3430.4895821716004, 5899.414111995351, 1769.320644862802, 6326.2158845598815, 15798.36978965918, 59430.17528032143, 20936.258144774198, 3475.7187993849866, 3594.953857743338, 3505.6239331834913, 4028.112854992427, 3841.802259448998, 3160.8159835417114, 2539.438590499329, 2013.0886205353936, 1851.834747970789, 1612.4816431182344, 1600.7967848725455, 2045.3128483082864, 1751.0091400899294, 1804.6263257067085, 1385.7882610412034, 1378.8367597596775, 1395.8295729542288, 11158.535068897801, 1247.982991978837, 1236.22150367512, 1185.1970307442334, 1224.8468962984866, 1568.2763422181233, 1136.3929067607355, 2256.1760729488133, 1194.136832956158, 1197.3704077148675, 1396.0645521103163, 1012.2979324220939, 2025.6351515420765, 837.6279825514534, 10074.05859054029, 7136.40520083793, 3140.6310409844045, 3329.8846391378415, 2962.2568657515662, 1831.9557400743274, 2783.9592100460854, 1768.7658280653015, 3809.048051432069, 6998.3911025825, 2654.5439601937896, 6015.365406319515, 2818.1447124274537, 8409.044083487044, 3105.349483886277, 4560.044181921418, 8474.105000832693, 3979.833595453897, 10758.004782683867, 3542.024185759164, 59430.17528032143, 18121.704024383, 7605.7422791541085, 6374.323001086454, 4423.44109573622, 2463.618874730983, 2340.617595213073, 6716.431240454581, 2169.352460081095, 6108.276378118694, 2016.9355820154497, 16325.239205641881, 1845.0416599458777, 2218.063429689051, 2345.0502834002727, 13533.333495839219, 1562.8505707918573, 1301.4125286936555, 1264.7400158129058, 1310.952520641637, 1059.5492766545406, 1059.5426968888605, 1053.8682647596681, 1052.6571598433825, 1018.863522427513, 1301.3785616712998, 986.131117988889, 858.3710359389611, 803.787675230148, 802.9478118081751, 793.865052311725, 787.1767759018818, 5069.25486583301, 4073.0738056893515, 3433.724054630185, 4962.481752742743, 3350.565255362399, 1842.5063546389881, 5126.435213360918, 1277.5233333955164, 3645.8498762356394, 2972.022335930736, 1254.992752517586, 1852.5229684993187, 1316.1574024873632, 2461.9893044989362, 5592.173435660401, 2001.6466810829982, 2721.0302995029183, 16506.567259697065, 59430.17528032143, 10758.004782683867, 8474.105000832693], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.166500091552734, -4.582300186157227, -4.809700012207031, -4.870500087738037, -4.909200191497803, -5.279200077056885, -5.2947001457214355, -5.007299900054932, -5.4278998374938965, -5.555799961090088, -5.474100112915039, -4.9085001945495605, -5.633399963378906, -5.724699974060059, -5.746099948883057, -5.729599952697754, -5.673299789428711, -5.792399883270264, -5.536099910736084, -5.729000091552734, -5.939199924468994, -5.423699855804443, -6.014599800109863, -6.116700172424316, -6.12060022354126, -6.120500087738037, -5.849800109863281, -6.118800163269043, -4.244500160217285, -6.156599998474121, -1.0952999591827393, -3.6777000427246094, -3.4486000537872314, -4.699699878692627, -4.05019998550415, -4.957300186157227, -4.942599773406982, -5.139400005340576, -5.331500053405762, -5.002600193023682, -5.446300029754639, -5.62939977645874, -5.627600193023682, -4.995200157165527, -4.595799922943115, -5.588099956512451, -5.350800037384033, -5.333799839019775, -4.235000133514404, -3.7155001163482666, -3.5797998905181885, -5.156300067901611, -3.7344000339508057, -4.671000003814697, -3.1696999073028564, -3.9084999561309814, -4.279799938201904, -4.749499797821045, -3.8362998962402344, -3.8615000247955322, -4.182499885559082, -4.305200099945068, -4.306700229644775, -4.455900192260742, -4.738100051879883, -4.820000171661377, -4.86299991607666, -4.902200222015381, -4.9243998527526855, -4.971399784088135, -4.994699954986572, -5.270699977874756, -5.059800148010254, -5.313799858093262, -5.037199974060059, -5.356200218200684, -5.203800201416016, -5.400400161743164, -5.412199974060059, -5.412600040435791, -5.434999942779541, -5.434299945831299, -4.718200206756592, -5.447000026702881, -5.4471001625061035, -5.435200214385986, -5.436399936676025, -5.474299907684326, -2.1928999423980713, -3.584700107574463, -4.052800178527832, -4.683800220489502, -4.881100177764893, -4.31820011138916, -3.6851999759674072, -5.009799957275391, -4.74560022354126, -4.729700088500977, -4.31689977645874, -3.9374001026153564, -4.288400173187256, -3.676500082015991, -3.964099884033203, -4.325099945068359, -4.338099956512451, -3.180299997329712, -4.263500213623047, -4.4847002029418945, -4.871600151062012, -3.032399892807007, -3.5099000930786133, -3.5429000854492188, -3.5727999210357666, -2.6041998863220215, -4.578499794006348, -4.607600212097168, -4.5208001136779785, -4.7322998046875, -4.869699954986572, -4.533699989318848, -4.90310001373291, -5.090400218963623, -5.049300193786621, -5.132299900054932, -5.1554999351501465, -5.157800197601318, -5.292900085449219, -5.304500102996826, -5.340000152587891, -5.324100017547607, -5.531300067901611, -5.555300235748291, -5.557300090789795, -5.183800220489502, -5.246699810028076, -5.610499858856201, -5.059800148010254, -5.672699928283691, -5.0441999435424805, -1.973099946975708, -3.80679988861084, -4.291800022125244, -4.959499835968018, -4.860799789428711, -5.177199840545654, -4.161799907684326, -4.7428998947143555, -5.050899982452393, -5.048699855804443, -5.0746002197265625, -4.190499782562256, -4.125999927520752, -4.432799816131592, -4.612599849700928, -4.660200119018555, -4.5447001457214355, -4.5920000076293945, -3.3469998836517334, -4.483699798583984, -4.67579984664917, -4.315700054168701, -2.550800085067749, -4.157599925994873, -3.9918999671936035, -4.18720006942749, -4.417799949645996, -4.535399913787842, -4.581399917602539, -3.2681000232696533, -4.745500087738037, -4.144599914550781, -4.824999809265137, -4.897299766540527, -4.946899890899658, -4.956099987030029, -4.991499900817871, -5.000400066375732, -4.812699794769287, -3.3580000400543213, -5.025199890136719, -5.098999977111816, -5.103600025177002, -5.144700050354004, -5.32390022277832, -5.327099800109863, -5.334499835968018, -5.332099914550781, -5.3796000480651855, -5.3231000900268555, -5.376699924468994, -5.494100093841553, -1.8575999736785889, -4.513199806213379, -4.7118000984191895, -4.884300231933594, -4.6682000160217285, -4.062699794769287, -4.951700210571289, -3.306299924850464, -4.633999824523926, -4.693600177764893, -4.701099872589111, -4.3333001136779785, -4.785699844360352, -4.970099925994873, -4.602399826049805, -4.079699993133545, -4.099699974060059, -3.9855000972747803, -4.304800033569336, -4.417900085449219, -4.504300117492676, -4.563000202178955, -4.643700122833252, -4.536200046539307, -4.866199970245361, -4.890699863433838, -4.4222002029418945, -4.820400238037109, -4.899499893188477, -4.978700160980225, -4.98330020904541, -4.981900215148926, -5.143700122833252, -5.143099784851074, -5.213799953460693, -5.223499774932861, -5.311999797821045, -5.343100070953369, -3.4683001041412354, -5.110199928283691, -5.51039981842041, -5.520500183105469, -5.537799835205078, -5.1442999839782715, -5.564499855041504, -3.317699909210205, -3.5578999519348145, -3.6993000507354736, -3.281100034713745, -4.375800132751465, -4.119800090789795, -4.597700119018555, -4.639200210571289, -4.086299896240234, -4.537600040435791, -4.676000118255615, -4.569900035858154, -3.937000036239624, -4.616099834442139, -4.882500171661377, -3.214900016784668, -4.326399803161621, -4.327300071716309, -4.601500034332275, -4.40500020980835, -4.352499961853027, -4.610199928283691, -3.59689998626709, -3.881200075149536, -3.7506000995635986, -4.115600109100342, -4.208700180053711, -4.216100215911865, -4.35830020904541, -4.36359977722168, -4.528600215911865, -4.547800064086914, -4.295599937438965, -4.622499942779541, -4.721099853515625, -4.751100063323975, -4.680099964141846, -4.948299884796143, -4.978700160980225, -4.917799949645996, -4.974899768829346, -5.010300159454346, -4.361199855804443, -4.995200157165527, -5.071100234985352, -5.046500205993652, -5.112100124359131, -5.161200046539307, -5.109899997711182, -5.183899879455566, -5.230800151824951, -5.213799953460693, -3.276900053024292, -4.207900047302246, -4.425899982452393, -4.358399868011475, -4.472599983215332, -3.5346999168395996, -4.6230998039245605, -4.399899959564209, -4.916399955749512, -4.868599891662598, -4.375999927520752, -3.0406999588012695, -3.942500114440918, -4.760000228881836, -4.540800094604492, -4.711699962615967, -3.75819993019104, -4.200300216674805, -4.207399845123291, -4.320899963378906, -4.366399765014648, -4.381499767303467, -4.387499809265137, -4.675099849700928, -4.648600101470947, -4.672100067138672, -4.684100151062012, -4.751699924468994, -4.5883002281188965, -4.81220006942749, -4.696800231933594, -4.822000026702881, -4.844099998474121, -4.927299976348877, -4.959099769592285, -4.963600158691406, -5.001800060272217, -3.461899995803833, -4.679200172424316, -5.06790018081665, -5.09089994430542, -5.097099781036377, -5.084400177001953, -5.116300106048584, -5.168300151824951, -4.856400012969971, -4.046800136566162, -3.866499900817871, -4.288000106811523, -4.5208001136779785, -3.98580002784729, -4.808599948883057, -4.89900016784668, -4.1793999671936035, -4.210000038146973, -3.364500045776367, -3.3947999477386475, -3.8821001052856445, -4.612400054931641, -3.553100109100342, -4.0746002197265625, -4.414999961853027, -3.559799909591675, -4.001800060272217, -4.138999938964844, -4.373899936676025, -3.572499990463257, -3.956199884414673, -3.8640999794006348, -4.654099941253662, -4.5802998542785645, -4.774099826812744, -4.188199996948242, -4.89109992980957, -4.89739990234375, -4.913099765777588, -4.918300151824951, -4.934999942779541, -5.032199859619141, -5.077600002288818, -5.058700084686279, -4.881499767303467, -5.031300067901611, -5.058700084686279, -5.056700229644775, -5.264400005340576, -4.168600082397461, -5.308700084686279, -4.0665998458862305, -5.354100227355957, -5.448599815368652, -5.449999809265137, -4.0706000328063965, -4.367400169372559, -3.868799924850464, -4.633699893951416, -4.853000164031982, -4.86329984664917, -4.979599952697754, -4.531499862670898, -4.91480016708374, -4.118500232696533, -4.17080020904541, -3.660099983215332, -4.82450008392334, -3.8958001136779785, -3.290600061416626, -2.671299934387207, -3.9765000343322754, -4.677000045776367, -4.076499938964844, -4.1016998291015625, -3.9628000259399414, -4.010200023651123, -4.2052998542785645, -4.424200057983398, -4.656599998474121, -4.740099906921387, -4.878600120544434, -4.885900020599365, -4.6407999992370605, -4.796199798583984, -4.76609992980957, -5.030200004577637, -5.035200119018555, -5.0229997634887695, -2.9442999362945557, -5.135000228881836, -5.144499778747559, -5.186699867248535, -5.153800010681152, -4.906599998474121, -5.228799819946289, -4.543000221252441, -5.179200172424316, -5.176499843597412, -5.0229997634887695, -5.3445000648498535, -4.650899887084961, -5.53410005569458, -3.0499000549316406, -3.400099992752075, -4.212699890136719, -4.155200004577637, -4.271299839019775, -4.752299785614014, -4.340099811553955, -4.7895002365112305, -4.031899929046631, -3.4391000270843506, -4.410600185394287, -3.634999990463257, -4.394999980926514, -3.4489998817443848, -4.327199935913086, -4.111000061035156, -3.9086999893188477, -4.395299911499023, -3.921799898147583, -4.5553998947143555, -3.797800064086914, -4.439899921417236, -3.300100088119507, -3.476799964904785, -3.8422000408172607, -4.427599906921387, -4.478799819946289, -3.4247000217437744, -4.554900169372559, -3.519700050354004, -4.627699851989746, -2.536600112915039, -4.716899871826172, -4.532700061798096, -4.477099895477295, -2.724299907684326, -4.882999897003174, -5.066100120544434, -5.094699859619141, -5.058899879455566, -5.271900177001953, -5.271900177001953, -5.277200222015381, -5.27839994430542, -5.310999870300293, -5.066299915313721, -5.343699932098389, -5.482600212097168, -5.548399925231934, -5.5493998527526855, -5.560800075531006, -5.569300174713135, -3.7067999839782715, -3.9256999492645264, -4.0971999168396, -3.734999895095825, -4.1244001388549805, -4.719699859619141, -3.706700086593628, -5.08519983291626, -4.054800033569336, -4.258999824523926, -5.104499816894531, -4.729499816894531, -5.060400009155273, -4.524600028991699, -3.8808999061584473, -4.716700077056885, -4.645500183105469, -4.07289981842041, -3.695499897003174, -4.266900062561035, -4.350200176239014], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1049, 2.1048, 2.1048, 2.1047, 2.1047, 2.1045, 2.1045, 2.1045, 2.1044, 2.1044, 2.1043, 2.1043, 2.1043, 2.1042, 2.1042, 2.1042, 2.1042, 2.1041, 2.1041, 2.1041, 2.104, 2.104, 2.1038, 2.1038, 2.1038, 2.1038, 2.1038, 2.1038, 2.1037, 2.1037, 2.1028, 2.1034, 2.0924, 2.1022, 2.0956, 2.102, 2.1016, 2.1019, 2.1035, 2.0987, 2.1029, 2.1031, 2.1028, 2.0896, 2.012, 2.0981, 2.0664, 2.0353, 1.7495, 1.5321, 1.4104, 1.928, 1.0181, 1.587, 0.5395, 0.6973, 0.6171, 0.547, 2.1202, 2.1202, 2.1201, 2.1201, 2.1201, 2.12, 2.12, 2.1199, 2.1199, 2.1199, 2.1199, 2.1198, 2.1198, 2.1197, 2.1197, 2.1197, 2.1197, 2.1197, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1196, 2.1176, 2.1181, 2.1194, 2.1193, 2.1144, 2.1086, 2.0904, 2.1148, 2.1077, 2.1067, 2.0962, 2.0537, 2.0601, 2.0126, 1.8538, 1.8955, 1.8902, 1.4255, 1.7425, 1.5716, 0.376, 2.2464, 2.2464, 2.2464, 2.2464, 2.2462, 2.2462, 2.2462, 2.2461, 2.2461, 2.246, 2.246, 2.246, 2.246, 2.246, 2.2459, 2.2459, 2.2459, 2.2458, 2.2458, 2.2458, 2.2458, 2.2456, 2.2456, 2.2456, 2.2456, 2.2456, 2.2456, 2.2455, 2.2455, 2.2455, 2.2435, 2.2452, 2.242, 2.2452, 2.2429, 2.2449, 2.2253, 2.2345, 2.2326, 2.2315, 2.232, 2.0052, 1.981, 1.9613, 2.007, 1.9891, 1.7941, 1.8095, 0.3622, 1.5736, 1.3805, 0.29, 2.2624, 2.2623, 2.2623, 2.2622, 2.2622, 2.2622, 2.2621, 2.2621, 2.2621, 2.2621, 2.2621, 2.262, 2.262, 2.262, 2.262, 2.262, 2.2619, 2.2619, 2.2619, 2.2619, 2.2619, 2.2619, 2.2618, 2.2618, 2.2618, 2.2618, 2.2617, 2.2617, 2.2617, 2.2617, 2.2549, 2.2605, 2.2607, 2.2598, 2.2411, 2.2093, 2.235, 1.9902, 2.138, 1.9802, 1.9392, 0.9143, 1.623, 2.1476, -0.8932, 2.3063, 2.3063, 2.3062, 2.3062, 2.3062, 2.3061, 2.3061, 2.3061, 2.306, 2.306, 2.306, 2.306, 2.306, 2.306, 2.306, 2.306, 2.3059, 2.3059, 2.3059, 2.3058, 2.3058, 2.3057, 2.3057, 2.3056, 2.3056, 2.3056, 2.3056, 2.3056, 2.3056, 2.3055, 2.305, 2.305, 2.3049, 2.299, 2.3049, 2.3021, 2.3051, 2.3055, 2.2995, 2.3019, 2.3018, 2.2949, 2.2564, 2.2743, 2.2927, 1.5377, 1.9487, 1.7931, 1.9317, 1.1573, -0.6433, 0.4239, 2.3548, 2.3548, 2.3547, 2.3547, 2.3547, 2.3547, 2.3547, 2.3547, 2.3546, 2.3546, 2.3546, 2.3546, 2.3546, 2.3546, 2.3545, 2.3545, 2.3544, 2.3544, 2.3544, 2.3544, 2.3544, 2.3544, 2.3544, 2.3544, 2.3544, 2.3543, 2.3543, 2.3543, 2.3543, 2.3543, 2.3535, 2.3538, 2.3542, 2.3532, 2.3534, 2.3439, 2.3525, 2.3256, 2.3488, 2.3457, 2.2901, 1.8562, -0.2333, 1.825, 0.8775, 1.4087, 2.3902, 2.3902, 2.3902, 2.3902, 2.3901, 2.3901, 2.3901, 2.39, 2.39, 2.39, 2.39, 2.39, 2.39, 2.39, 2.39, 2.39, 2.3899, 2.3899, 2.3899, 2.3899, 2.3899, 2.3899, 2.3899, 2.3898, 2.3898, 2.3898, 2.3898, 2.3898, 2.3898, 2.3898, 2.3893, 2.3871, 2.388, 2.3896, 2.3811, 2.3889, 2.3893, 2.3816, 2.3819, 2.3598, 2.2803, 2.233, 2.3489, 2.0092, 0.9595, 0.1908, 2.4089, 2.4088, 2.4088, 2.4087, 2.4087, 2.4086, 2.4086, 2.4086, 2.4086, 2.4085, 2.4085, 2.4085, 2.4085, 2.4085, 2.4085, 2.4084, 2.4084, 2.4084, 2.4083, 2.4083, 2.4083, 2.4083, 2.4083, 2.4082, 2.4082, 2.4082, 2.4082, 2.4081, 2.4081, 2.4081, 2.408, 2.4074, 2.3996, 2.4059, 2.4079, 2.4074, 2.4079, 2.3988, 2.4063, 2.3895, 2.3905, 2.3591, 2.3989, 2.0535, 1.7435, 1.0379, 0.776, 1.8712, 2.4379, 2.4379, 2.4379, 2.4379, 2.4379, 2.4378, 2.4377, 2.4377, 2.4376, 2.4376, 2.4376, 2.4376, 2.4376, 2.4375, 2.4375, 2.4375, 2.4375, 2.4375, 2.4374, 2.4374, 2.4374, 2.4374, 2.4374, 2.4374, 2.4374, 2.4374, 2.4374, 2.4373, 2.4373, 2.4371, 2.4341, 2.4287, 2.4368, 2.4358, 2.4368, 2.4363, 2.43, 2.4343, 2.4248, 2.4092, 2.4071, 2.3647, 2.363, 2.2157, 2.3337, 2.1657, 1.7483, 2.0175, 1.4965, 1.974, -0.0886, 0.457, 2.465, 2.4649, 2.4649, 2.4648, 2.4647, 2.4647, 2.4647, 2.4647, 2.4647, 2.4647, 2.4646, 2.4646, 2.4646, 2.4646, 2.4645, 2.4645, 2.4644, 2.4644, 2.4643, 2.4643, 2.4643, 2.4643, 2.4643, 2.4643, 2.4642, 2.4641, 2.464, 2.464, 2.464, 2.464, 2.464, 2.4639, 2.4632, 2.4571, 2.4605, 2.4632, 2.4529, 2.4638, 2.4456, 2.4458, 2.4624, 2.448, 2.4589, 2.3684, 2.1917, 2.3833, 2.1475, 0.9173, 0.0137, 1.1515, 1.3068]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 8, 2, 7, 5, 7, 8, 9, 10, 3, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 4, 3, 7, 1, 2, 4, 5, 6, 8, 9, 10, 4, 5, 6, 8, 1, 1, 9, 5, 5, 8, 9, 10, 3, 4, 7, 6, 5, 7, 8, 9, 10, 3, 7, 9, 10, 7, 6, 5, 6, 8, 2, 7, 7, 6, 10, 1, 1, 2, 3, 4, 5, 6, 7, 9, 9, 7, 8, 5, 4, 6, 7, 9, 10, 6, 1, 2, 9, 10, 1, 3, 10, 9, 10, 7, 4, 7, 10, 10, 4, 4, 8, 6, 2, 3, 1, 5, 9, 4, 1, 3, 4, 6, 7, 1, 2, 3, 6, 10, 1, 9, 6, 8, 9, 10, 1, 8, 9, 1, 3, 2, 1, 8, 1, 3, 1, 9, 1, 6, 9, 10, 3, 7, 8, 9, 1, 6, 3, 7, 10, 4, 2, 3, 6, 3, 5, 8, 1, 3, 1, 2, 3, 5, 7, 8, 4, 2, 7, 8, 1, 1, 7, 9, 10, 3, 4, 8, 3, 2, 7, 10, 2, 1, 2, 4, 5, 6, 8, 9, 2, 5, 9, 3, 4, 8, 9, 10, 4, 9, 8, 1, 4, 5, 6, 8, 1, 1, 4, 8, 9, 2, 3, 10, 4, 6, 8, 6, 9, 8, 10, 2, 4, 5, 1, 7, 1, 2, 5, 10, 1, 2, 5, 8, 10, 1, 3, 2, 9, 1, 3, 6, 7, 8, 9, 10, 7, 5, 10, 1, 3, 5, 2, 7, 10, 6, 3, 2, 3, 9, 9, 6, 3, 5, 6, 10, 5, 2, 5, 6, 5, 2, 5, 8, 1, 2, 3, 4, 5, 7, 9, 10, 8, 2, 3, 9, 1, 6, 8, 1, 3, 5, 6, 7, 1, 1, 2, 4, 3, 4, 5, 3, 5, 7, 9, 5, 8, 1, 5, 8, 10, 2, 2, 6, 4, 3, 9, 1, 3, 4, 7, 9, 10, 1, 5, 10, 5, 1, 3, 1, 2, 5, 6, 8, 10, 2, 6, 7, 2, 7, 10, 1, 2, 9, 2, 3, 6, 1, 3, 4, 9, 1, 2, 5, 7, 1, 5, 9, 6, 3, 6, 1, 2, 5, 8, 1, 4, 8, 10, 2, 4, 3, 1, 5, 6, 7, 8, 1, 7, 3, 8, 7, 6, 4, 3, 2, 5, 6, 7, 5, 7, 8, 10, 3, 7, 2, 4, 5, 1, 6, 6, 8, 9, 4, 5, 2, 5, 6, 7, 8, 6, 9, 10, 1, 3, 6, 8, 5, 9, 3, 6, 1, 7, 1, 7, 10, 4, 9, 5, 1, 2, 1, 5, 6, 8, 10, 1, 4, 8, 6, 9, 5, 10, 6, 9, 7, 5, 6, 10, 8, 4, 10, 4, 5, 6, 7, 4, 10, 2, 10, 3, 8, 5, 3, 4, 7, 5, 6, 7, 9, 10, 2, 3, 4, 5, 6, 9, 10, 7, 3, 1, 2, 5, 10, 6, 5, 1, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 3, 8, 2, 5, 6, 7, 8, 3, 10, 1, 4, 5, 6, 7, 8, 10, 2, 10, 7, 2, 4, 8, 10, 5, 10, 1, 4, 6, 10, 1, 6, 10, 7, 3, 3, 5, 6, 10, 7, 8, 4, 5, 1, 1, 3, 1, 2, 6, 7, 9, 10, 9, 10, 5, 10, 3, 4, 5, 7, 8, 9, 10, 4, 6, 1, 3, 9, 7, 2, 7, 9, 10, 7, 2, 5, 8, 1, 5, 6, 2, 3, 5, 6, 7, 9, 8, 1, 9, 7, 1, 2, 3, 4, 6, 7, 8, 9, 4, 8, 9, 7, 5, 6, 7, 9, 2, 5, 3, 6, 1, 2, 3, 4, 5, 6, 9, 8, 9, 2, 1, 3, 4, 9, 10, 8, 1, 2, 4, 9, 5, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 10, 4, 1, 2, 7, 9, 3, 2, 6, 9, 1, 7, 9, 5, 7, 2, 4, 5, 3, 8, 3, 8, 10, 2, 4, 5, 6, 8, 9, 4, 9, 3, 6, 2, 9, 5, 1, 5, 7, 9, 10, 2, 3, 4, 6, 7, 9, 9, 1, 6, 9, 3, 8, 9, 6, 7, 2, 3, 6, 1, 7, 10, 7, 8, 4, 5, 1, 2, 5, 7, 2, 5, 8, 1, 2, 2, 3, 5, 8, 1, 3, 8, 1, 4, 7, 4, 5, 1, 8, 4, 5, 7, 8, 9, 7, 1, 2, 5, 6, 7, 2, 4, 9, 7, 6, 8, 10, 4, 8, 2, 7, 8, 10, 10, 7, 5, 5, 4, 7, 9, 10, 2, 5, 2, 7, 10, 8, 1, 8, 9, 3, 5, 5, 1, 2, 4, 6, 8, 9, 1, 2, 5, 6, 9, 1, 3, 8, 2, 1, 5, 7, 9, 5, 5, 7, 8, 10, 9, 4, 1, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 9, 5, 8, 1, 2, 10, 5, 9, 9, 3, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 5, 7, 3, 4, 1, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 10, 4, 5, 6, 8, 4, 10, 5, 8, 6, 7, 8, 6, 6, 10, 1, 2, 6, 10, 4, 5, 7, 8, 9, 1, 2, 4, 5, 6, 7, 3, 5, 7, 5, 3, 6, 7, 2, 2, 3, 5, 8, 10, 8, 6, 1, 3, 5, 7, 9, 9, 4, 1, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 7, 1, 5, 10, 1, 4, 1, 2, 6, 8, 2, 7, 7, 10, 8, 3, 1, 3, 10, 2, 2, 3, 2, 6, 7, 8, 10, 1, 2, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 2, 3, 6, 4, 4], \"Freq\": [0.0007503152695410014, 0.0003751576347705007, 0.002250945808623004, 0.0007503152695410014, 0.5985640062763338, 0.38810057317008295, 0.009003783234492016, 0.9998750558318674, 0.9992381493240629, 0.0004800261377144651, 0.990773948242656, 0.00024001306885723255, 0.0009600522754289302, 0.007440405134574209, 0.9993800376782654, 0.002282236046418636, 0.995562079804396, 0.0017750724805478278, 0.004554747928618754, 9.295403935956642e-05, 0.002881575220146559, 0.00027886211807869927, 0.09007246413941986, 0.22820216662773557, 9.295403935956642e-05, 0.014965600336890194, 0.38994219511338113, 0.2688230818278661, 0.00012016386958717733, 0.00036049160876153196, 0.00036049160876153196, 0.0033645883484409653, 0.00012016386958717733, 0.8957014839028198, 0.0009613109566974186, 0.09901502853983411, 0.999886031451914, 0.9998761408766157, 0.9997117769827253, 0.33721403085403845, 4.776402703314992e-05, 0.0006209323514309489, 0.46354988235672, 4.776402703314992e-05, 0.19535487056558318, 0.003009133703088445, 0.00014329208109944977, 0.9994983097050864, 0.0005754205433287328, 0.41516592201168073, 0.5840518514786639, 0.9992429457961414, 0.9974904467280196, 0.0018767459016519653, 0.9995056414111764, 0.08732775548907462, 0.0036555804623333563, 0.000812351213851857, 0.9078024814794502, 0.0010814709464194384, 0.9978371932296686, 0.0007209806309462923, 0.9992409535877169, 0.9995395075215003, 0.0005653659654278897, 0.0005653659654278897, 0.9961748310839417, 0.0028268298271394484, 0.9991059732136188, 0.001050131147202551, 0.9865982127967967, 0.012076508192829337, 0.9993695697162323, 0.9996361805559666, 0.9994216971246254, 0.9994825931213793, 0.998879954931755, 0.9940180433871996, 0.0053998264013790835, 0.9994048590859066, 0.011899106779115633, 0.9878209299908454, 0.9980075517942679, 0.044744802353409094, 0.0002182673285532151, 0.0034922772568514414, 0.9481532752351663, 0.0006548019856596453, 0.0002182673285532151, 0.001964405956978936, 0.0004365346571064302, 0.9997346675976707, 0.9997175210503385, 0.9986241686705905, 0.9991038653291864, 0.1718387947136068, 0.0028540699468003897, 0.023427157479986534, 0.8005666200775093, 0.001308115392283512, 0.9996255805516087, 0.012101492738425005, 0.9876379557488795, 0.9992374621154108, 0.9988195847921415, 0.0006944956584291348, 0.999379252479525, 0.9989103282614521, 0.9997013031929449, 0.9985050678095355, 0.9990874607282944, 0.002686113928268069, 0.0017907426188453794, 0.9953544389748901, 0.9991761164191939, 0.9993162319930882, 0.00021843394869698732, 0.9995537492374139, 0.9996789949320664, 0.9994171682213991, 0.9996912435532854, 0.999349094728497, 0.9883180054094605, 0.011055894587081458, 0.9993550450893388, 5.267318451793003e-05, 0.999684368965794, 5.267318451793003e-05, 5.267318451793003e-05, 0.00010534636903586006, 0.0004666929811494546, 0.354219972692436, 0.6361025333067066, 0.009100513132414364, 0.0002333464905747273, 0.9996739973427275, 0.9994311821918515, 7.389162472848592e-05, 0.00022167487418545777, 0.00022167487418545777, 0.9994581160775006, 0.01749021489871957, 0.9814925593998133, 0.0008745107449359786, 0.998743473176094, 0.9998629890819724, 0.9995581839594216, 0.9997152003305061, 0.9993401048044295, 0.9986610747938767, 0.9997446047604779, 0.0004936723176622994, 0.999192770948494, 0.9992247405293704, 0.9997387585848804, 0.0007827645678628116, 0.9988075885929476, 0.9986724686880203, 0.0010825695990225542, 0.9984900268318024, 0.00036085653300751806, 0.9995048959757749, 0.9995675244520401, 0.9986321139730677, 0.001051007311671357, 0.9994815940450879, 0.9994627111460855, 0.0005893139856659364, 0.005303825870993428, 0.9935833798327689, 0.00016950835812096793, 0.04830988206447586, 0.951280905774872, 0.9964483938919912, 0.003307320415952555, 0.005240118669808532, 0.897888240910448, 0.07835805359736944, 0.00012186322487926818, 0.0034121702966195093, 0.014867313435270719, 0.9994715323744952, 0.9995584221361098, 0.9996125961711028, 0.999633937939468, 0.9994035846131997, 0.012419518361018513, 0.059613688132888865, 0.9275605998772113, 0.9997361400622058, 0.001089661472794604, 0.9730676952055815, 0.025607044610673195, 0.9988057222005761, 0.0005918029531756483, 0.00039453530211709886, 0.9989633849604943, 0.998925390413225, 0.2258065794747645, 0.005187150163887553, 0.02372845287735795, 5.518244855199524e-05, 0.6072276638661556, 5.518244855199524e-05, 0.1379009389314361, 0.9990698305821339, 0.998751936147425, 0.999358118583486, 0.6459562029834223, 0.001242223467275812, 0.35229457531942027, 0.0002484446934551624, 0.0002484446934551624, 0.9998650239202441, 0.9997237279509069, 0.9998217902202088, 0.9974098900834688, 0.0015657926060964973, 0.000163185238960569, 0.000163185238960569, 0.9996727738724456, 0.9978935980885598, 0.003479744784582849, 0.00043496809807285614, 0.9906398433609298, 0.005219617176874274, 0.24684575752114907, 0.7518808338481353, 0.0012329957918139314, 0.9994616647372432, 0.9996410573289698, 0.9992619639645325, 0.9996271928370964, 0.9987178355496702, 0.9987876282266885, 0.9990200456483456, 0.47123934162952463, 0.5275478131465948, 0.0010010394936368022, 0.9965305357954108, 0.002876820253450955, 0.0004277119340852456, 0.0004277119340852456, 0.9991350780231337, 0.9993765604686273, 0.0003278347621456626, 0.0007649477783398794, 0.9925743815230178, 0.006010303972670481, 0.0002185565080971084, 0.013204489544835274, 0.9861352873711071, 0.007902414633307726, 0.9917530364801195, 0.9976330675071572, 1.0092903712956217e-05, 3.0278711138868648e-05, 5.046451856478108e-05, 1.0092903712956217e-05, 0.00224062462427628, 1.0092903712956217e-05, 0.9991162993309487, 0.9993595183183243, 0.9991524650667093, 0.13982972188313697, 0.5101847661151736, 0.3497504126699119, 0.001345884905251675, 0.017496503768271773, 0.980813624702158, 0.9998223673996401, 0.999893164177496, 0.999292995123661, 0.00038434345966294653, 0.999827288401078, 0.9989900154040364, 0.9996496680825551, 0.7667434890906372, 0.008328133480347255, 0.2130151474639931, 0.011474317239589549, 0.9997299833297818, 0.0013049210587089027, 0.9985545923698015, 0.9993740125359749, 0.9988434244734256, 0.9995641971395633, 0.9988094027342658, 0.0008203773328412861, 0.00016482654502052646, 0.9355554695365081, 0.002472398175307897, 0.00016482654502052646, 0.0003296530900410529, 0.0011537858151436852, 0.05966720929743057, 0.0004944796350615793, 0.9989875354488466, 0.21418194988260145, 0.7855360654806648, 0.999741844021936, 0.9934506973640015, 0.001500680811728099, 0.004502042435184297, 0.990384661784321, 0.0003847648258680346, 0.00846482616909676, 0.0001923824129340173, 0.0003847648258680346, 0.9997202999385523, 0.9929502974414006, 0.001795570158121882, 0.004488925395304704, 0.9996140451547039, 0.0013360415610793792, 0.998524061711701, 0.00026530030825932724, 0.9991209609046264, 0.00026530030825932724, 0.00013265015412966362, 0.986125301355054, 0.012925727598318568, 0.9967664733352085, 0.002878055264682989, 0.9989606225368968, 0.9995361368881625, 0.9992210043262127, 0.9998761175389915, 0.9995304240617371, 0.9996336899156404, 0.9996585454217083, 0.9995022573258049, 0.0022282374739171318, 0.7731984034492447, 0.0006366392782620377, 0.02737548896526762, 0.1788956371916326, 0.017507580152206034, 0.9986072812874108, 0.0006983267701310565, 0.9999024054291002, 0.9994626001990128, 0.9996706567813994, 0.9997484435878381, 0.00025482951756261357, 0.9884836986253781, 0.0010193180702504543, 0.010193180702504544, 0.016733935571720496, 0.9829837637452589, 0.9864658033628513, 0.00038383883399332737, 0.012666681521779802, 0.9997180444582238, 0.9592955828452113, 0.040441744879693854, 0.31986261974724983, 0.02336781118342045, 0.6565601142180392, 0.02032706392503421, 0.9791277297865875, 0.0004898087692779327, 0.04326180284832625, 0.7870557989620498, 0.16903004398596044, 0.0003090128774880447, 0.9993042288572704, 0.794354683769747, 0.20516998933768846, 0.00020893074270640372, 0.9970975776040527, 0.00074161218118561, 0.0018540304529640252, 0.9995914439121688, 0.9992861253598225, 0.9994939083866231, 0.9991050856585382, 0.00047029804094891734, 0.0018811921637956694, 0.9970318468117048, 0.9618502253006989, 0.028128287615783634, 0.009604781137096851, 0.9996742138744407, 0.9989873911134558, 0.0007424655452348241, 0.998879408510331, 0.7007567125343147, 0.0008186410193157882, 0.2961843207884522, 0.0004911846115894729, 0.0016372820386315763, 0.9982484086818394, 0.9997307236535099, 0.9852550534704961, 0.014357086389369708, 0.9996553698419417, 0.9989369814103675, 0.9999062962959211, 0.9995543846639233, 0.0003798565209157322, 0.0003798565209157322, 0.99864279348746, 0.0003798565209157322, 0.00026837354874984534, 0.00026837354874984534, 0.9991547219956741, 0.9997924483766781, 0.9994360469785866, 0.999470789678446, 0.9998338825993507, 0.8831277678880676, 0.11659877620038056, 0.000874861248740071, 0.9987999256449143, 0.00565188680131827, 0.9902105675909608, 0.0039563207609227885, 0.004421376017633819, 0.9952517415693727, 0.9989980504935969, 0.0003387505140789816, 0.9982977649907587, 0.0006775010281579632, 0.0006775010281579632, 0.5886520775985031, 0.1110439010479935, 0.29999763589578887, 0.0006894484800074795, 0.9983213990508302, 0.9997902595283359, 0.9995758906678496, 0.9991836114477597, 0.9993931408096319, 0.9996308062561898, 0.9995233756059475, 0.9993799737253668, 0.9995415929125132, 0.0006538980462927059, 0.9975214696195228, 0.0016347451157317646, 0.9995359712775727, 0.9991861496703329, 0.99910115974846, 0.0005926812690421968, 0.9990630591821297, 0.008820188442732283, 0.00036750785178051173, 0.2627681140230659, 0.00036750785178051173, 0.7280330543771938, 0.0002079118121328275, 0.9996399927346347, 0.00010395590606641375, 0.9997335384365355, 0.9994592287074257, 0.999536318943602, 0.9988529740434561, 0.9889562965629057, 0.010898401481110206, 0.9994632592059784, 0.9996493506813781, 0.9991671606518275, 0.0003628057954436556, 0.9996269085158354, 0.001628216908151617, 0.9980969646969412, 0.00030057773579297663, 0.005410399244273579, 0.0027051996221367897, 0.9916059503810298, 0.000982059297431026, 0.9987543054873534, 0.9993624751428336, 0.9994354274114828, 0.0005346692102949523, 0.9992967540412658, 0.9996519332726619, 0.00032619552339040186, 0.7541640500786091, 0.24529903358958222, 0.6992974562891893, 0.2773982082399508, 0.0002189409694080117, 0.0002189409694080117, 0.022988801787841226, 0.7660576777969729, 0.0004158084011924948, 0.0004158084011924948, 0.2299420458594496, 0.0008316168023849896, 0.0006930140019874913, 0.0016632336047699792, 0.9993166340732753, 0.9994997909992929, 0.0043885515155989065, 0.00027428446972493166, 0.014262792425696445, 0.9805669792666306, 0.9995049978940577, 0.9993149418492812, 0.10049759837851512, 0.05543461832266848, 0.08297310613457476, 0.7608848418159818, 0.20895109162014971, 0.03706871113216217, 0.151943014763243, 0.04260461942198575, 0.05234714495331662, 0.07514701040228608, 0.012030925310710826, 0.25382728435254936, 0.07990890111967233, 0.08616834757503516, 0.9995519974248176, 0.0002395026143237549, 0.999683912187353, 0.9998474137890078, 0.0004411593154039338, 0.9974612121282943, 0.0008823186308078676, 0.0008823186308078676, 0.0003675290710549861, 0.9995565635792105, 0.2104854377281562, 0.7616314353447278, 0.0012342773909000558, 0.0005759961157533594, 0.0004114257969666853, 0.025014688455574464, 0.0004937109563600223, 0.9994392343103755, 0.9994148870094617, 0.9996516995214058, 0.9973199761262139, 0.00033771031975953067, 0.00184205628959744, 0.0004912150105593173, 0.005318512806121006, 0.9938021072008965, 0.9989665428441875, 0.8914010643072445, 0.10780206824480082, 0.9995205593876094, 0.0010342234704597132, 0.9984853038693831, 0.00034474115681990436, 0.9991014166994054, 0.9997261323009571, 0.0012090724558702559, 0.00020151207597837598, 0.006448386431308031, 0.9920439500415449, 0.009696830157920031, 0.989919878730271, 0.9971871924477944, 0.002088350141251925, 0.9989178305963192, 0.011489783613875803, 0.9881213907933191, 8.961749851800003e-05, 0.00026885249555400005, 8.961749851800003e-05, 0.00017923499703600005, 0.9993247259742183, 8.961749851800003e-05, 0.9997911762774815, 0.9992734133184543, 0.9992419898904626, 0.9994878008310056, 0.0012611391515357415, 0.0022420251582857625, 0.001821645441107182, 0.0002802531447857203, 0.0005605062895714406, 0.9905547402451285, 0.0030827845926429233, 0.9998321330346284, 0.9991390491878341, 0.9991139783908004, 0.0007661917012199389, 0.9994056774764608, 0.9997744360906785, 0.9993197505732776, 0.9984995995850713, 0.0005507444013155385, 0.0005507444013155385, 0.9995306653680229, 0.031193818711924937, 0.9682237236558519, 0.9994513129321166, 0.006603794386316897, 0.9930150077202445, 0.999705992875731, 0.0032864696560774794, 0.016146568310293704, 0.0008573399102810816, 0.008001839162623427, 0.00014288998504684693, 0.9715090083335123, 0.9995483768189988, 0.9992523713457916, 0.9996529332982753, 0.9993912438400169, 0.0010028936583201143, 0.0020057873166402286, 0.9963748495410335, 0.04305640347765148, 0.01845274434756492, 0.00016624094006815243, 0.008977010763680232, 0.929120614040904, 0.00031840734774326066, 0.0006368146954865213, 0.9985254425228655, 0.999332504483443, 9.92648584493063e-05, 0.0024816214612326574, 0.0013897080182902883, 0.9959243248218901, 0.9998486300800566, 0.9995502883803026, 0.9997317047212635, 0.9996507982379558, 0.5638102950518988, 0.17474592883470944, 7.836140306489212e-05, 0.2596896897570525, 0.0007836140306489212, 0.0007836140306489212, 7.836140306489212e-05, 0.9998348307381136, 0.9998220193622067, 0.9993858207174633, 0.013334741543667001, 0.17087350225867096, 0.00011800656233333629, 0.5016458964790126, 0.3140154623690079, 0.9996343462870314, 0.0287081448557381, 0.24733170952635902, 0.7236976296600353, 0.9995492319324368, 0.07793583226965692, 0.9212415045208164, 0.9991099813995056, 0.0006962743717519543, 0.01284942704233152, 0.07747634827494473, 0.0024053114660522058, 0.15216759906288166, 6.329767015926857e-05, 0.2390753001915574, 0.5139770816932608, 0.0012026557330261029, 0.9997833269824832, 0.001119467171429356, 0.13321659340009337, 0.8543400296625036, 0.011194671714293562, 0.9988734776694204, 0.9763090456117429, 0.001256834507739113, 0.022371654237756212, 0.9994377519911875, 0.0016375941483598735, 0.9983865657834029, 0.9985148520052349, 0.001368297159308304, 0.9978404885035769, 0.00012354097913873678, 0.0018531146870810517, 0.9858086605972451, 0.014126853080209743, 0.9992349410197469, 0.9971418217134842, 0.0018696409157127828, 0.000158072379799851, 0.000158072379799851, 0.298124508302519, 0.000474217139399553, 0.7007348596527395, 0.000158072379799851, 0.9787718012988947, 0.02064048505480588, 0.9996682411831295, 0.9997624264013885, 0.9996233552926209, 0.9993085696660979, 0.999436200776993, 0.00012622235612683776, 0.02991469840206055, 0.9697663621224946, 0.00012622235612683776, 0.9989406912700871, 0.6854052068293078, 0.0018402385343232574, 0.00033458882442241047, 0.3078217184686176, 0.0006691776488448209, 0.0038477714808577202, 0.9987742736227508, 0.005179631999617836, 0.9371896649308522, 0.05729967899577231, 0.9990238596216883, 0.9993547061659921, 0.00030201109282743794, 0.9993706695873433, 0.0003401533933244872, 0.9992299739380449, 0.9989380674936053, 0.0006039528824024216, 0.5955903107987593, 0.4040198819549228, 0.00021524767285824336, 0.9994139384200983, 0.000430163818545236, 0.9994313946067491, 0.9997016354093706, 0.9845451916555823, 0.009840531650730459, 0.004920265825365229, 0.9995278065752345, 0.9989888908983514, 0.9997660169364218, 0.9998560094646193, 0.058203377020477017, 0.9416222452381626, 0.5777270360657446, 0.4206289108505467, 0.0007036870110423199, 0.0008796087638028999, 0.9992753048246532, 0.0005921078298171035, 0.9991819628163621, 0.9979769800758336, 0.9993541311257675, 0.9996428318001181, 0.9992457252974108, 0.9993390142346259, 0.999213233759553, 0.9990504809229328, 0.00025718818626528254, 0.00025718818626528254, 0.9989189154543575, 0.00025718818626528254, 0.00025718818626528254, 0.9995885215870524, 0.8375026931640566, 0.0034424655620366386, 0.1067164324231358, 0.04229314833359299, 0.009835615891533254, 0.9990907478112608, 0.9996654456241149, 0.9992502846555572, 0.9995094705970654, 0.9996038388849509, 0.9994670131108913, 0.9995521275566212, 0.9996298674082594, 0.9994253731062696, 0.0004132932403644077, 0.9989297619607734, 0.9987382781692324, 0.0005868027486305714, 0.9993757133201087, 0.9995187699140708, 0.9993022080606372, 0.9997574592214544, 0.9995295555425161, 0.00014888859339120072, 0.00014888859339120072, 0.9996380160285216, 0.9995492179111674, 0.9994237408603621, 0.9943674254626724, 0.0025601632993374674, 0.0025601632993374674, 0.9992815640283912, 0.99861218526627, 0.23837488336395507, 0.7613961315912162, 0.004235226333093471, 0.9956632088527015, 0.9989090230790548, 0.00690947495058831, 0.0008291369940705972, 0.009396885932800102, 0.0016582739881411943, 0.9805926849874929, 0.0002763789980235324, 0.0019929606288564676, 0.9705718262530998, 0.0006643202096188226, 0.026572808384752903, 0.00013286404192376452, 0.9323747832255129, 0.06669160441024005, 0.9996230358999537, 0.9994640175352039, 0.9990434906065276, 0.00045785677846311995, 0.0010127413441706574, 0.9985629653522683, 0.9992684595928355, 0.31687360166653006, 0.6830171840799901, 0.00010734200598459691, 0.9994557568025033, 0.9988554855656715, 0.9996185488643666, 0.0004432278189587411, 0.9990355039330023, 0.9873294840589005, 0.0016812762606366973, 0.00010507976628979358, 0.0010507976628979358, 0.0026269941572448397, 0.0003152392988693807, 0.006199706211097822, 0.00010507976628979358, 0.00042031906515917433, 0.00010507976628979358, 0.09886165843587956, 0.9007037740884531, 0.9985049247678359, 0.001313822269431363, 0.9976481206303647, 0.0009402904058721628, 0.0009402904058721628, 0.002102174927541156, 0.9976321584702457, 0.9994236808553281, 0.9996304641605608, 0.9990733250733611, 0.9990119054946961, 0.00016769737271524158, 0.00041924343178810394, 0.9969888303542304, 0.0005589912423841386, 5.589912423841386e-05, 2.794956211920693e-05, 0.001621074602914002, 0.00011179824847682773, 2.794956211920693e-05, 2.794956211920693e-05, 0.00020176046009495502, 0.048018989502599294, 0.951098808887618, 0.0006052813802848651, 0.0013193884035672865, 0.9983372253659134, 0.3712566405636091, 0.6287365312054428, 0.999748794451394, 0.999697083546398, 0.005138010806702324, 5.037265496766985e-05, 0.0007304034970312128, 0.992492420827999, 0.0004281675672251937, 2.5186327483834923e-05, 7.555898245150478e-05, 0.0010830120818049018, 0.9994334795724782, 0.00011371412897627469, 0.00011371412897627469, 0.00022742825795254938, 0.9998410820192902, 0.9995677441066552, 0.9997078775946067, 0.999105630640611, 0.9998443321170897, 0.9996976531979594, 0.999471797925746, 0.9997919645962262, 0.0003274246082191824, 0.999627328893164, 0.9108769186394232, 0.08763716917516409, 0.0006107119803147323, 0.00030535599015736614, 0.9993714725081374, 0.9997404788080978, 0.0011851049589921092, 0.998450927950852, 0.9992123354363361, 0.0002834174106673311, 0.30212295977137493, 0.008785939730687264, 0.6872872208682779, 0.0002834174106673311, 0.0011336696426693244, 0.9954429969136265, 0.003686825914494913, 0.0005672039868453712, 0.9991908060931834, 0.9984552637102228, 0.0011093947374558031, 0.9996398767972035, 0.9997366044151564, 0.9994388033100334, 0.0005824579867747706, 0.0002912289933873853, 0.0008736869801621559, 0.9980417603385694, 0.9994451367862612, 0.9995931950696691, 0.027500015480877847, 0.0018835627041697155, 0.0003767125408339431, 0.0007534250816678862, 0.9692813675657356, 0.9990479876972359, 0.9997913324001855, 0.0006031005354420575, 0.9987344866920473, 0.9996759022712075, 0.24465068012374763, 0.49915832460177306, 0.1413381457828866, 0.00012372758603695935, 0.0015672160898014852, 4.1242528678986456e-05, 0.1108186745604366, 0.0022270965486652686, 0.9993279877170222, 0.0007968173505336534, 0.0007968173505336534, 0.9976153228681341, 0.9989924777542681, 0.9991783433321672, 0.9997537177327371, 0.002240165680413044, 0.9907132721626688, 0.0067204970412391325, 0.008451409071778042, 0.9911462845902455, 0.9996194528222745, 0.9996830146594105, 0.9995806243538989, 0.9998437416641506, 0.9985537828382931, 0.00023556352508570253, 0.0009422541003428101, 0.9993961980351507, 0.7986688623155171, 0.20111858682400094, 0.00021429617052057392, 0.00021429617052057392, 0.9966914890911893, 0.002571554046246887, 0.00021429617052057392, 0.9982566487567655, 0.0004007989756785728, 0.0005343986342380971, 0.00013359965855952428, 0.00013359965855952428, 0.00026719931711904855, 0.00026719931711904855, 0.4991952518267704, 0.01878040389154112, 0.04355842063876795, 0.0010904750646701295, 0.08384541608352551, 0.0015145487009307354, 0.0005452375323350648, 0.028534097525535054, 0.11019856347972032, 0.2127032195587125, 0.9995662769193852, 0.027483386604600417, 0.0010306269976725155, 0.9711941741400671, 0.9987520239747052, 0.9997742063504488], \"Term\": [\"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"abraham\", \"absence\", \"abundance\", \"abundance\", \"abundance\", \"abundance\", \"abundance\", \"accomplishment\", \"achievement\", \"achievement\", \"achievement\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"aim\", \"albert\", \"alcott\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"anger\", \"answer\", \"answer\", \"answer\", \"anthony\", \"anxiety\", \"anxiety\", \"arise\", \"ask\", \"ask\", \"ask\", \"ask\", \"asset\", \"asset\", \"asset\", \"attain\", \"attempt\", \"attention\", \"attention\", \"attention\", \"attention\", \"attitude\", \"attract\", \"attract\", \"attract\", \"b\", \"bach\", \"bar\", \"battle\", \"beat\", \"beauty\", \"beauty\", \"benefit\", \"benjamin\", \"benjamin\", \"bertrand\", \"bhajan\", \"bhajan\", \"bhajan\", \"bhajan\", \"bhajan\", \"bhajan\", \"bhajan\", \"bhajan\", \"bind\", \"bite\", \"bittersweet\", \"blessing\", \"body\", \"body\", \"body\", \"body\", \"body\", \"bonaparte\", \"brault\", \"brault\", \"breath\", \"brick\", \"bridge\", \"bridge\", \"brinkley\", \"buddha\", \"buffet\", \"buffett\", \"business\", \"business\", \"business\", \"buy\", \"c\", \"care\", \"care\", \"carl\", \"case\", \"cash\", \"celebrate\", \"challenge\", \"challenge\", \"chance\", \"change\", \"change\", \"change\", \"change\", \"change\", \"character\", \"character\", \"character\", \"character\", \"character\", \"child\", \"childhood\", \"choice\", \"choice\", \"choice\", \"choice\", \"choose\", \"choose\", \"choose\", \"chop\", \"churchill\", \"clement\", \"climb\", \"coco\", \"commitment\", \"communication\", \"conflict\", \"conflict\", \"confuciu\", \"confucius\", \"connection\", \"connection\", \"conscience\", \"consent\", \"consent\", \"consent\", \"consist\", \"content\", \"control\", \"control\", \"controversy\", \"conversation\", \"count\", \"count\", \"count\", \"courage\", \"courage\", \"courage\", \"covey\", \"covey\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"creation\", \"cross\", \"cruelty\", \"dalai\", \"dale\", \"dance\", \"dance\", \"dance\", \"danger\", \"dare\", \"dare\", \"dare\", \"darkness\", \"david\", \"david\", \"david\", \"dawn\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"deal\", \"death\", \"decide\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"defeat\", \"define\", \"denis\", \"deserve\", \"deserve\", \"desire\", \"desire\", \"desire\", \"destination\", \"difference\", \"difference\", \"difference\", \"difference\", \"difficulty\", \"difficulty\", \"difficulty\", \"dig\", \"discourage\", \"discouragement\", \"discover\", \"disease\", \"disney\", \"distance\", \"dog\", \"dog\", \"dog\", \"door\", \"door\", \"doubt\", \"doubt\", \"doubt\", \"dr\", \"dream\", \"dream\", \"dream\", \"dream\", \"dream\", \"drive\", \"drive\", \"drucker\", \"drucker\", \"dyer\", \"dyer\", \"dyer\", \"dyer\", \"dyer\", \"dyer\", \"dyer\", \"earth\", \"ease\", \"edge\", \"edison\", \"edison\", \"edison\", \"effort\", \"effort\", \"effort\", \"ego\", \"einstein\", \"eleanor\", \"eleanor\", \"eliot\", \"elliot\", \"emerson\", \"end\", \"end\", \"end\", \"end\", \"enemy\", \"energy\", \"energy\", \"enjoy\", \"enthusiasm\", \"existence\", \"expectation\", \"expectation\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"expertise\", \"eye\", \"eye\", \"fact\", \"fail\", \"fail\", \"fail\", \"failure\", \"failure\", \"failure\", \"failure\", \"failure\", \"fall\", \"family\", \"family\", \"family\", \"fantasy\", \"fear\", \"fear\", \"feel\", \"feel\", \"feel\", \"feel\", \"feeling\", \"feeling\", \"fight\", \"fight\", \"find\", \"finger\", \"fire\", \"fool\", \"foot\", \"force\", \"forget\", \"forgiveness\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"fortune\", \"fortune\", \"franklin\", \"freedom\", \"frustration\", \"fuller\", \"future\", \"future\", \"future\", \"future\", \"gain\", \"gain\", \"game\", \"game\", \"game\", \"gandhi\", \"genius\", \"genius\", \"george\", \"george\", \"george\", \"get\", \"get\", \"get\", \"gift\", \"gift\", \"gift\", \"gift\", \"glory\", \"goal\", \"goal\", \"goal\", \"god\", \"god\", \"god\", \"goethe\", \"gogh\", \"greatness\", \"ground\", \"grow\", \"grow\", \"grow\", \"guidance\", \"guidance\", \"guidance\", \"habit\", \"hand\", \"hand\", \"hang\", \"happiness\", \"happiness\", \"happiness\", \"happiness\", \"happiness\", \"harder\", \"harm\", \"harry\", \"harry\", \"hate\", \"heal\", \"heart\", \"hell\", \"help\", \"help\", \"help\", \"help\", \"hemingway\", \"hemingway\", \"hemingway\", \"henry\", \"hepburn\", \"hill\", \"history\", \"hoffer\", \"hoffer\", \"hold\", \"hold\", \"honor\", \"honor\", \"honor\", \"hope\", \"hope\", \"hubbard\", \"huie\", \"huie\", \"huie\", \"huie\", \"idea\", \"idea\", \"idea\", \"ignorance\", \"ignorance\", \"imagination\", \"impact\", \"imperfection\", \"impossibility\", \"influence\", \"inspiration\", \"inspire\", \"intent\", \"intention\", \"intention\", \"intention\", \"jack\", \"jefferson\", \"jerry\", \"jim\", \"jim\", \"job\", \"job\", \"job\", \"job\", \"job\", \"john\", \"john\", \"john\", \"jonathan\", \"journey\", \"joy\", \"jr\", \"judge\", \"judge\", \"judgment\", \"jump\", \"jung\", \"jung\", \"kennedy\", \"kill\", \"kill\", \"kind\", \"kind\", \"kind\", \"kind\", \"king\", \"king\", \"knowledge\", \"lady\", \"lama\", \"lama\", \"lao\", \"lead\", \"lead\", \"lead\", \"leader\", \"leader\", \"leader\", \"leader\", \"leader\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"lengthen\", \"lesson\", \"let\", \"let\", \"let\", \"let\", \"letter\", \"lewis\", \"lie\", \"lie\", \"lie\", \"lie\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"limit\", \"limit\", \"lincoln\", \"lockwood\", \"lockwood\", \"lockwood\", \"lockwood\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"mahatma\", \"mail\", \"make\", \"man\", \"man\", \"man\", \"man\", \"management\", \"management\", \"mandela\", \"mark\", \"mark\", \"martin\", \"matter\", \"matter\", \"matter\", \"maxwell\", \"maya\", \"mean\", \"mean\", \"mean\", \"mean\", \"mediocrity\", \"mediocrity\", \"meet\", \"meet\", \"memory\", \"michael\", \"michael\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"miracle\", \"mirror\", \"mistake\", \"mlk\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"monroe\", \"mother\", \"mountain\", \"mountain\", \"music\", \"napoleon\", \"nature\", \"need\", \"need\", \"need\", \"nietzsche\", \"night\", \"night\", \"norman\", \"obstacle\", \"obstacle\", \"opinion\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"oprah\", \"optimism\", \"order\", \"page\", \"pain\", \"pain\", \"pain\", \"passion\", \"passion\", \"passion\", \"passion\", \"passion\", \"path\", \"path\", \"path\", \"patience\", \"peace\", \"peace\", \"peace\", \"peace\", \"peale\", \"percent\", \"perception\", \"perfection\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"pessimist\", \"peter\", \"pickford\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plant\", \"play\", \"play\", \"play\", \"pocket\", \"point\", \"point\", \"position\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"ppl\", \"practice\", \"practice\", \"practice\", \"practice\", \"precede\", \"presence\", \"presence\", \"presence\", \"pressure\", \"prevent\", \"prevent\", \"problem\", \"problem\", \"proverb\", \"proverb\", \"proverb\", \"pull\", \"pull\", \"push\", \"quality\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"race\", \"race\", \"rain\", \"ralph\", \"rate\", \"react\", \"read\", \"reality\", \"reality\", \"reality\", \"reality\", \"rearview\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"receive\", \"refuse\", \"refuse\", \"refuse\", \"reject\", \"relationship\", \"relationship\", \"release\", \"release\", \"repeat\", \"reputation\", \"reputation\", \"respect\", \"respect\", \"respect\", \"result\", \"result\", \"reward\", \"rice\", \"rise\", \"rise\", \"rise\", \"risk\", \"river\", \"road\", \"robert\", \"rohn\", \"rohn\", \"roosevelt\", \"roosevelt\", \"roosevelt\", \"roosevelt\", \"root\", \"rule\", \"rule\", \"russell\", \"ruth\", \"sail\", \"scott\", \"sea\", \"search\", \"seed\", \"self\", \"self\", \"self\", \"self\", \"self\", \"seneca\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"shadow\", \"shakespeare\", \"shell\", \"ship\", \"shoe\", \"shore\", \"show\", \"shut\", \"sight\", \"silence\", \"silence\", \"sir\", \"sir\", \"slip\", \"smile\", \"solution\", \"solve\", \"sort\", \"soul\", \"soul\", \"soul\", \"source\", \"space\", \"speak\", \"speak\", \"speak\", \"speech\", \"speed\", \"spirit\", \"spirit\", \"stand\", \"stand\", \"star\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stephen\", \"stephen\", \"stevenson\", \"stone\", \"stop\", \"stop\", \"storm\", \"storm\", \"strategy\", \"strength\", \"strength\", \"strength\", \"strengthen\", \"stress\", \"strike\", \"stuff\", \"stuff\", \"success\", \"success\", \"success\", \"success\", \"success\", \"success\", \"success\", \"success\", \"success\", \"success\", \"suit\", \"suit\", \"sun\", \"sun\", \"talent\", \"talent\", \"talent\", \"talk\", \"talk\", \"teach\", \"teacher\", \"tension\", \"thatcher\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"thinking\", \"thinking\", \"thomas\", \"thomas\", \"thoreau\", \"till\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"today\", \"today\", \"today\", \"today\", \"tomorrow\", \"tooth\", \"tracy\", \"travel\", \"treat\", \"trouble\", \"truman\", \"trust\", \"truth\", \"truth\", \"try\", \"try\", \"try\", \"try\", \"twain\", \"tzu\", \"understand\", \"understand\", \"universe\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"value\", \"value\", \"value\", \"version\", \"victor\", \"victor\", \"victory\", \"vincent\", \"voltaire\", \"wait\", \"wait\", \"wait\", \"wait\", \"waitley\", \"waldo\", \"want\", \"want\", \"want\", \"want\", \"want\", \"war\", \"waste\", \"watch\", \"watch\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"weakness\", \"wealth\", \"wealth\", \"wealth\", \"weather\", \"wilde\", \"william\", \"willingness\", \"willingness\", \"willingness\", \"win\", \"win\", \"wind\", \"windshield\", \"winfrey\", \"winston\", \"wisdom\", \"wisdom\", \"wisdom\", \"wise\", \"woman\", \"woman\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worry\", \"year\", \"year\", \"year\", \"yesterday\", \"yogi\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 10, 2, 9, 3, 7, 8, 1, 4, 6]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el56021397746459953448123915690\", ldavis_el56021397746459953448123915690_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el56021397746459953448123915690\", ldavis_el56021397746459953448123915690_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el56021397746459953448123915690\", ldavis_el56021397746459953448123915690_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "4     -0.004427 -0.058685       1        1  12.182810\n",
              "9      0.222194 -0.202481       2        1  11.999511\n",
              "1      0.080771 -0.097124       3        1  10.576748\n",
              "8      0.044011 -0.223311       4        1  10.409093\n",
              "2      0.085282  0.213443       5        1   9.961151\n",
              "6     -0.165460 -0.074812       6        1   9.489423\n",
              "7      0.214846  0.210101       7        1   9.158813\n",
              "0     -0.002775  0.180721       8        1   8.990485\n",
              "3     -0.231550 -0.013117       9        1   8.732032\n",
              "5     -0.242893  0.065266      10        1   8.499934, topic_info=       Term          Freq         Total Category  logprob  loglift\n",
              "1336   dyer  99079.000000  99079.000000  Default  30.0000  30.0000\n",
              "100    time  39704.000000  39704.000000  Default  29.0000  29.0000\n",
              "60    thing  35778.000000  35778.000000  Default  28.0000  28.0000\n",
              "212     man  32572.000000  32572.000000  Default  27.0000  27.0000\n",
              "58    heart  19702.000000  19702.000000  Default  26.0000  26.0000\n",
              "...     ...           ...           ...      ...      ...      ...\n",
              "121     job   1980.628947   2721.030300  Topic10  -4.6455   2.1475\n",
              "136   world   3511.207457  16506.567260  Topic10  -4.0729   0.9173\n",
              "65     life   5120.974221  59430.175280  Topic10  -3.6955   0.0137\n",
              "101     act   2892.138397  10758.004783  Topic10  -4.2669   1.1515\n",
              "316   place   2660.878743   8474.105001  Topic10  -4.3502   1.3068\n",
              "\n",
              "[531 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "150       1  0.000750    ability\n",
              "150       2  0.000375    ability\n",
              "150       3  0.002251    ability\n",
              "150       4  0.000750    ability\n",
              "150       5  0.598564    ability\n",
              "...     ...       ...        ...\n",
              "38        2  0.027483       year\n",
              "38        3  0.001031       year\n",
              "38        6  0.971194       year\n",
              "256       4  0.998752  yesterday\n",
              "3167      4  0.999774       yogi\n",
              "\n",
              "[980 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 10, 2, 9, 3, 7, 8, 1, 4, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmVuxe3aPbub"
      },
      "source": [
        "This base model appears to be a great start. A coherence score of .61 will need to be compared to other strategies before commenting on how good it is. As can be seen in LDA visualization there is nice serperability between the 10 topics. Looking at some of the categoies some of the seem reasonable. Words like peace and mind seem like they would go togther, but it isn't clear how words like life and power go together. It should be noted that there are many first and last names appearing in the topics, but that isn't suprising since our n-grams are nouns. \n",
        "\n",
        "# Optimal Topic Model\n",
        "In order to find the best model the focus will be on tuning 3 parameters (number of topics, alpha, and beta). Number of topics is self-explanatory. Alpha relates to document-topic density (scaled 0-1). The higher the alpha the more unique topic distribution per documents. Beta relates to topic-word density (scaled 0-1). The higher the beta the more unique word distribution per topics.\n",
        "\n",
        "In addition to tuning these 3 parameters several different strategies will be explored as well. I will be evaluating the following approaches: no n-grams, n-grams only, nouns only n-grams, nouns and verbs only n-grams. \n",
        "\n",
        "The goal it to select the strategy that has the highest coherence score (metric - coherence score), most seperable topics (metric - eyeballing pyLDAvis for non-overlapping topics), and most explanatory topics (metric - subjectively evaluating the topic). It is unlikely that all 3 of the goals will be met by one strategy. So explanatory topics will be the prefered evalutation metric, because at the end of the day I want topics that make sense to the user. \n",
        "\n",
        "My hunch is that the noun and verb n-grams strategy will perfom best. Focusing on nouns makes it more likely the topic will be extracted from the text. But adding verbs makes sense because of the call-to-action nature of motivational tweets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Msw50ipaxD"
      },
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           alpha=a,\n",
        "                                           eta=b,\n",
        "                                           random_state=222)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHqifw2LoPta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586afd2c-fa35-4d26-bf1d-2225f9cdea0f"
      },
      "source": [
        "# start preprocess runtime\n",
        "start_time = time.time() \n",
        "\n",
        "# Topics range\n",
        "min_topics = 3\n",
        "max_topics = 10\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "# Alpha parameter\n",
        "alpha = [.01,.1,.5,1,'symmetric','asymmetric']\n",
        "# Beta parameter\n",
        "beta = [.01,.1,.5,1,'symmetric']\n",
        "\n",
        "# model results dict\n",
        "model_results = {'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=210)\n",
        "\n",
        "    # iterate through number of topics\n",
        "    for k in topics_range:\n",
        "        # iterate through alpha values\n",
        "        for a in alpha:\n",
        "            # iterare through beta values\n",
        "            for b in beta:\n",
        "                # get the coherence score for the given parameters\n",
        "                cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
        "                                              k=k, a=a, b=b)\n",
        "                # Save the model results\n",
        "                model_results['Topics'].append(k)\n",
        "                model_results['Alpha'].append(a)\n",
        "                model_results['Beta'].append(b)\n",
        "                model_results['Coherence'].append(cv)\n",
        "                \n",
        "                pbar.update(1)\n",
        "    lda_tuning_results = pd.DataFrame(model_results)                \n",
        "    lda_tuning_results.to_csv('/content/drive/MyDrive/Data/NLP_Capstone/lda_tuning_nouns_3-10_topics.csv', index=False)\n",
        "    pbar.close()\n",
        "\n",
        "# print preprocess runtime\n",
        "print(time.strftime(f'%H hours, %M minutes, %S seconds', time.gmtime(time.time() - start_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 210/210 [3:59:55<00:00, 68.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "03 hours, 59 minutes, 55 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIrLrAIDLN4K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "2136bc6f-b840-4a72-a282-1a400839f2ca"
      },
      "source": [
        "lda_tuning_results.sort_values('Coherence',ascending=False).head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topics</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Beta</th>\n",
              "      <th>Coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.623141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>9</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.616538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.615413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.614666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>9</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.614617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.613899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.612633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.611294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.611154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.610316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>9</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.609511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>9</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.608072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>9</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.607771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>9</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.607657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.607161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.605003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.602042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.601704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.596686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.595831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.595147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.594816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.593696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>7</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.589841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>9</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.587872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.587578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.587441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.586344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>1</td>\n",
              "      <td>0.585451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.585373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topics       Alpha       Beta  Coherence\n",
              "160       8         0.5       0.01   0.623141\n",
              "205       9  asymmetric       0.01   0.616538\n",
              "161       8         0.5        0.1   0.615413\n",
              "185       9         0.1       0.01   0.614666\n",
              "206       9  asymmetric        0.1   0.614617\n",
              "191       9         0.5        0.1   0.613899\n",
              "176       8  asymmetric        0.1   0.612633\n",
              "190       9         0.5       0.01   0.611294\n",
              "179       8  asymmetric  symmetric   0.611154\n",
              "164       8         0.5  symmetric   0.610316\n",
              "209       9  asymmetric  symmetric   0.609511\n",
              "201       9   symmetric        0.1   0.608072\n",
              "200       9   symmetric       0.01   0.607771\n",
              "180       9        0.01       0.01   0.607657\n",
              "194       9         0.5  symmetric   0.607161\n",
              "162       8         0.5        0.5   0.605003\n",
              "192       9         0.5        0.5   0.602042\n",
              "163       8         0.5          1   0.601704\n",
              "193       9         0.5          1   0.596686\n",
              "174       8   symmetric  symmetric   0.595831\n",
              "130       7         0.5       0.01   0.595147\n",
              "177       8  asymmetric        0.5   0.594816\n",
              "189       9         0.1  symmetric   0.593696\n",
              "145       7  asymmetric       0.01   0.589841\n",
              "204       9   symmetric  symmetric   0.587872\n",
              "166       8           1        0.1   0.587578\n",
              "186       9         0.1        0.1   0.587441\n",
              "155       8         0.1       0.01   0.586344\n",
              "178       8  asymmetric          1   0.585451\n",
              "171       8   symmetric        0.1   0.585373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-1S1Tk4YQaA"
      },
      "source": [
        "It seems that 8-9 topics are the sweet spot for these particular parameters. I will withold judgement before speculating on what these particular results means until all the other strategies have been attempted. These results will be compared to other strategies in the final step of the project -[optimized model deployment notebook](https://github.com/tarrantcarter/Final_Capstone/blob/main/Optimal_Deployed_Motivational_Tweet_Generator.ipynb). "
      ]
    }
  ]
}